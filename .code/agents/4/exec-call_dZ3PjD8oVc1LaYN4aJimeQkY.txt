
===== adaptation-guide.md =====
# Adaptation Guide: claude-code-collective → cc-sessions

## Overview

This guide provides step-by-step instructions for adapting agents from claude-code-sub-agent-collective to work with cc-sessions' architecture.

---

## Key Differences Between Systems

| Aspect | claude-code-collective | cc-sessions |
|--------|------------------------|-------------|
| **Task Management** | TaskMaster MCP (external service) | File-based tasks (sessions/tasks/*.md) |
| **Task State** | TaskMaster database | .claude/state/current_task.json |
| **Task Fetching** | `mcp__task-master__get_task --id=1.2` | Read JSON + read task file |
| **Task Updates** | `mcp__task-master__set_task_status` | Edit task file directly |
| **Research Cache** | `.taskmaster/docs/research/` | `sessions/research/` |
| **Context Storage** | TaskMaster task fields | Memory Bank MCP + task files |
| **Phase Control** | Prime directives + hub-and-spoke | DAIC modes (discussion/implementation) |

---

## Standard Adaptation Process

### Step 1: Copy Agent File

```bash
# From their repository
cp templates/agents/agent-name.md → cc_sessions/agents/agent-name.md
```

### Step 2: Remove TaskMaster MCP Calls

**Find and replace patterns:**

#### Pattern 1: Get Task
```markdown
# BEFORE (their code):
mcp__task-master__get_task --id=1.2 --projectRoot=/path/to/project

# AFTER (cc-sessions):
# Get current task from state
const currentTask = Read('.claude/state/current_task.json');
// Returns: { "task": "implement-auth", "branch": "feature/auth", ... }

# Load task file
const taskFile = Read(`sessions/tasks/${currentTask.task}.md`);
// Parse for acceptance criteria, test strategy, etc.
```

#### Pattern 2: Set Task Status
```markdown
# BEFORE (their code):
mcp__task-master__set_task_status --id=1.2 --status=done --projectRoot=/path

# AFTER (cc-sessions):
# Update task file directly
Edit('sessions/tasks/implement-auth.md',
     old: '## Status\nin-progress',
     new: '## Status\ncomplete');
```

#### Pattern 3: Update Task
```markdown
# BEFORE (their code):
mcp__task-master__update_task --id=1.2 --prompt="progress notes"

# AFTER (cc-sessions):
# Append to work log in task file
const currentLog = Grep(pattern: '## Work Log', path: 'sessions/tasks/implement-auth.md');
Edit('sessions/tasks/implement-auth.md',
     old: '## Work Log\n' + currentLog,
     new: '## Work Log\n' + currentLog + '\n- ' + timestamp + ': progress notes');
```

### Step 3: Update Tool Lists

```markdown
# BEFORE (their agent frontmatter):
tools: Read, Write, Edit, mcp__task-master__get_task, mcp__task-master__set_task_status

# AFTER (cc-sessions):
tools: Read, Write, Edit, Grep, LS
# Remove all mcp__task-master__* tools
# Keep Context7 tools if research agent
```

### Step 4: Add DAIC Mode Checkpoint

**Add to EVERY implementation agent at the very beginning:**

```markdown
## 🚨 CRITICAL: DAIC Mode Checkpoint (MANDATORY FIRST STEP)

Before any implementation work:

1. **Check DAIC Mode:**
   ```javascript
   const daicState = Read('.claude/state/daic-mode.json');
   const mode = JSON.parse(daicState).mode;
   ```

2. **Validate Implementation Mode:**
   ```javascript
   if (mode !== "implementation") {
       return `❌ CANNOT PROCEED

       This specialist can only run in implementation mode.
       Current mode: ${mode}

       User must:
       1. Approve implementation ("go ahead", "make it so")
       2. Wait for DAIC to unlock implementation mode
       3. Then retry specialist
       `;
   }
   ```

3. **Proceed with TDD workflow** (only if mode check passes)
```

### Step 5: Update File Paths

```markdown
# BEFORE (their paths):
.taskmaster/docs/research/
.taskmaster/docs/prd.txt
.taskmaster/tasks/

# AFTER (cc-sessions paths):
sessions/research/
sessions/docs/prd.md (if used)
sessions/tasks/
```

### Step 6: Keep TDD Structure

**DO NOT change the TDD workflow:**
- ✅ Keep RED-GREEN-REFACTOR structure
- ✅ Keep "max 5 initial tests" guideline
- ✅ Keep specialist boundaries
- ✅ Keep completion reporting format

### Step 7: Update Context Loading

**For agents that load research context:**

```markdown
# BEFORE (TaskMaster research):
const task = mcp__task-master__get_task(taskId);
const researchFiles = task.research_context?.research_files || [];

# AFTER (cc-sessions research):
// Check for research cache
const researchFiles = Glob(pattern: "*.md", path: "sessions/research/");

// Check Memory Bank if available
const memoryBankFiles = Glob(pattern: "*.md", path: ".claude/memory-bank/");

// Load relevant research
for (const file of researchFiles) {
    const research = Read(file);
    // Use research findings
}
```

---

## Agent-Specific Adaptations

### Implementation Agents

**Template for all implementation agents:**

```markdown
---
name: [agent-name]
description: [description]
tools: Read, Write, Edit, MultiEdit, Glob, Grep, LS, Bash
color: [color]
---

## 🚨 CRITICAL: DAIC Mode Checkpoint
[Insert mode checkpoint from Step 4]

## 🎯 TDD Workflow - Red-Green-Refactor
[Keep their TDD structure exactly]

## 📋 Task Loading (cc-sessions)
```javascript
// 1. Get current task
const currentTask = Read('.claude/state/current_task.json');

// 2. Load task file
const taskContent = Read(`sessions/tasks/${currentTask.task}.md`);

// 3. Parse acceptance criteria
const criteria = extractSection(taskContent, '## Success Criteria');

// 4. Parse test strategy
const testStrategy = extractSection(taskContent, '## Test Strategy');

// 5. Check for research context
const researchFiles = Glob(pattern: "*.md", path: "sessions/research/");
```

## 📚 Research Integration (if applicable)
[Keep their research loading, update paths]

## 🚀 Execution Process
[Keep their TDD workflow]

## 📋 Completion Reporting
[Keep their completion format]
```

### Validation Agents

**Template for validation agents:**

```markdown
---
name: [agent-name]
description: [description]
tools: Read, Bash, Grep, LS, Glob
color: [color]
---

## 🎯 Validation Protocol
[Keep their validation logic]

## 📋 Task Context Loading (cc-sessions)
```javascript
// Load current task
const currentTask = Read('.claude/state/current_task.json');
const taskContent = Read(`sessions/tasks/${currentTask.task}.md`);

// Parse acceptance criteria for validation
const criteria = extractSection(taskContent, '## Success Criteria');
```

## 🧪 Validation Execution
[Keep their validation steps]

## ✅ / ❌ Gate Decision
[Keep their PASS/FAIL logic]
```

### Research Agent

**Specific adaptations:**

```markdown
---
name: research-agent
description: Context7 integration for current documentation
tools: mcp__context7__resolve-library-id, mcp__context7__get-library-docs, Read, Write, Grep, LS, WebSearch, WebFetch
color: cyan
---

## 📋 Research Protocol

### 1. Check Existing Research
```javascript
// Check research cache first
const cacheFiles = Glob(pattern: "*.md", path: "sessions/research/");

// Check Memory Bank for project context
const memoryFiles = Glob(pattern: "*.md", path: ".claude/memory-bank/");
```

### 2. Query Context7 (if needed)
[Keep their Context7 integration]

### 3. Cache Results
```javascript
// Cache to sessions/research/
Write(`sessions/research/${timestamp}_${topic}.md`, researchContent);
```

### 4. Integration with Memory Bank
```javascript
// Memory Bank = project-specific knowledge
// Research cache = technical documentation
// They complement each other
```
```

---

## Common Helper Functions

Create these in each agent for consistency:

```javascript
// Load current task
function loadCurrentTask() {
    const state = Read('.claude/state/current_task.json');
    const taskState = JSON.parse(state);
    const taskContent = Read(`sessions/tasks/${taskState.task}.md`);
    return { state: taskState, content: taskContent };
}

// Extract section from markdown
function extractSection(markdown, heading) {
    const lines = markdown.split('\n');
    const startIdx = lines.findIndex(l => l.startsWith(heading));
    if (startIdx === -1) return '';

    const endIdx = lines.findIndex((l, i) =>
        i > startIdx && l.startsWith('## ')
    );

    return lines.slice(startIdx + 1, endIdx === -1 ? undefined : endIdx).join('\n');
}

// Check DAIC mode
function checkDAICMode() {
    const state = Read('.claude/state/daic-mode.json');
    const mode = JSON.parse(state).mode;
    return mode;
}

// Update task status
function updateTaskStatus(taskName, newStatus) {
    const taskPath = `sessions/tasks/${taskName}.md`;
    const content = Read(taskPath);
    const updated = content.replace(
        /## Status\n[^\n]+/,
        `## Status\n${newStatus}`
    );
    Write(taskPath, updated);
}

// Append to work log
function appendWorkLog(taskName, entry) {
    const taskPath = `sessions/tasks/${taskName}.md`;
    const content = Read(taskPath);
    const timestamp = new Date().toISOString();
    const logEntry = `\n- ${timestamp}: ${entry}`;

    if (content.includes('## Work Log')) {
        const updated = content.replace(
            /## Work Log\n/,
            `## Work Log\n${logEntry}\n`
        );
        Write(taskPath, updated);
    }
}
```

---

## Testing Adaptations

### For Each Adapted Agent:

1. **Isolation Test:**
   - Create test task file
   - Set DAIC mode to implementation
   - Invoke agent
   - Verify it reads task correctly
   - Verify TDD workflow works

2. **Mode Check Test:**
   - Set DAIC mode to discussion
   - Try to invoke implementation agent
   - Verify it refuses to proceed

3. **Integration Test:**
   - Full workflow: discussion → approve → specialist → validation
   - Verify all steps work together

---

## Validation Checklist

After adapting an agent, verify:

- [ ] All TaskMaster MCP calls removed
- [ ] Task loading uses current_task.json + task file
- [ ] DAIC mode checkpoint added (implementation agents)
- [ ] File paths updated (sessions/tasks/, sessions/research/)
- [ ] Tool list updated (no TaskMaster tools)
- [ ] TDD structure preserved
- [ ] Specialist boundaries preserved
- [ ] Completion reporting format preserved
- [ ] Helper functions work correctly
- [ ] All tests pass

---

## Example: Complete Adaptation

**Before (from their repo):**
```markdown
---
name: feature-implementation-agent
tools: Read, Write, Edit, mcp__task-master__get_task
---

I implement features using TDD.

## Process:
1. Fetch task: mcp__task-master__get_task --id=1.2
2. Write tests
3. Implement
```

**After (cc-sessions):**
```markdown
---
name: feature-implementation-agent
tools: Read, Write, Edit, Grep, LS
---

I implement features using TDD.

## 🚨 DAIC Mode Checkpoint
1. Check mode: Read('.claude/state/daic-mode.json')
2. If not "implementation" → refuse
3. If "implementation" → proceed

## Process:
1. Load task:
   ```javascript
   const state = Read('.claude/state/current_task.json');
   const task = Read(`sessions/tasks/${state.task}.md`);
   ```
2. Write tests (RED)
3. Implement (GREEN)
4. Refactor
```

---

## Troubleshooting

### Issue: Agent can't find task
**Solution:** Verify current_task.json exists and has correct format:
```json
{
  "task": "task-name",
  "branch": "feature/branch",
  "services": ["service"],
  "updated": "2025-01-03"
}
```

### Issue: Agent runs in discussion mode
**Solution:** Ensure DAIC mode checkpoint is at the very beginning of agent logic

### Issue: Research cache not found
**Solution:** Verify path is `sessions/research/`, create directory if needed

---

Last Updated: 2025-01-03

===== agent-inventory.md =====
# Agent Inventory - Complete Catalog

## Overview

This document catalogs all agents being integrated from claude-code-sub-agent-collective into cc-sessions, including their purpose, tools, adaptations needed, and integration status.

---

## Research Agents (1)

### @research-agent
**Purpose:** Context7 integration for current documentation during discussion phase

**Current Implementation:**
- Queries Context7 MCP for library documentation
- Caches research findings to `.taskmaster/docs/research/`
- Extracts working code examples
- Provides research-backed planning

**Tools:**
- `mcp__context7__resolve-library-id`
- `mcp__context7__get-library-docs`
- `Read`, `Write`, `Grep`, `LS`, `WebSearch`, `WebFetch`

**Adaptations Needed:**
- ✅ Change cache location: `.taskmaster/docs/research/` → `sessions/research/`
- ✅ Remove TaskMaster MCP calls (none in this agent)
- ✅ Add Memory Bank integration awareness
- ✅ Update to work during DAIC discussion mode

**Integration Phase:** Phase 1
**Status:** Not started
**Priority:** High
**Complexity:** Medium

---

## Implementation Agents (5)

### @component-implementation-agent
**Purpose:** UI component implementation with TDD enforcement

**Specialization:**
- React, Vue, HTML, CSS components
- Styling and responsive design
- User interactions and events
- **Boundary:** Cannot do backend/logic work

**TDD Workflow:**
- RED: Write 5 UI tests (render, interaction, props, state, key feature)
- GREEN: Minimal component code to pass tests
- REFACTOR: Styling, responsive design, accessibility

**Tools:**
- `Read`, `Write`, `Edit`, `MultiEdit`, `Glob`, `Grep`, `LS`, `Bash`
- `mcp__task-master__get_task`, `mcp__task-master__set_task_status`
- `mcp__context7__resolve-library-id`, `mcp__context7__get-library-docs`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls → Read current_task.json + task file
- ✅ Add DAIC mode checkpoint (refuse if not in implementation mode)
- ✅ Keep TDD structure (RED-GREEN-REFACTOR)
- ✅ Update completion reporting
- ✅ Add human confirmation requirement

**Integration Phase:** Phase 4
**Status:** Not started
**Priority:** High
**Complexity:** Medium

---

### @feature-implementation-agent
**Purpose:** Backend and business logic implementation with TDD

**Specialization:**
- APIs and web services
- Business logic and data processing
- State management
- Data services and persistence
- **Boundary:** Cannot do UI work

**TDD Workflow:**
- RED: Write 5 logic tests (happy path, validation, edge case, error, data flow)
- GREEN: Minimal backend code to pass tests
- REFACTOR: Error handling, validation, optimization

**Tools:**
- `Read`, `Write`, `Edit`, `MultiEdit`, `Glob`, `Grep`, `LS`, `Bash`
- `mcp__task-master__get_task`, `mcp__task-master__set_task_status`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls → Read current_task.json + task file
- ✅ Add DAIC mode checkpoint
- ✅ Keep TDD structure
- ✅ Update completion reporting
- ✅ Add human confirmation requirement

**Integration Phase:** Phase 2 (proof of concept)
**Status:** Not started
**Priority:** Critical (first specialist to prove)
**Complexity:** Medium

---

### @infrastructure-implementation-agent
**Purpose:** Project setup and build configuration with TDD

**Specialization:**
- Build configuration (Vite, webpack, etc.)
- Dependencies and package management
- Environment setup
- CI/CD configuration
- **Boundary:** Cannot add features, only setup/config

**TDD Workflow:**
- RED: Write 5 config tests (build, env, dependencies, scripts, deployment)
- GREEN: Minimal config to pass tests
- REFACTOR: Optimization, documentation

**Tools:**
- `Read`, `Write`, `Edit`, `MultiEdit`, `Glob`, `Grep`, `LS`, `Bash`
- `mcp__task-master__get_task`, `mcp__task-master__set_task_status`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls → Read current_task.json + task file
- ✅ Add DAIC mode checkpoint
- ✅ Keep TDD structure
- ✅ Update completion reporting
- ✅ Add human confirmation requirement

**Integration Phase:** Phase 4
**Status:** Not started
**Priority:** Medium
**Complexity:** Medium

---

### @testing-implementation-agent
**Purpose:** Add test coverage to existing code

**Specialization:**
- Unit tests for components/functions
- Integration tests
- Test utilities and fixtures
- **Boundary:** Cannot modify implementation, only add tests

**TDD Workflow:**
- RED: Write tests for existing code (expect them to pass against working code)
- GREEN: Adjust tests if needed to match actual behavior
- REFACTOR: Enhance test coverage, add edge cases

**Tools:**
- `Read`, `Write`, `Edit`, `MultiEdit`, `Bash`, `Glob`, `Grep`
- `mcp__task-master__get_task`, `mcp__task-master__set_task_status`, `LS`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls → Read current_task.json + task file
- ✅ Add DAIC mode checkpoint
- ✅ Keep TDD structure
- ✅ Update completion reporting
- ✅ Add human confirmation requirement

**Integration Phase:** Phase 4
**Status:** Not started
**Priority:** Medium
**Complexity:** Low

---

### @polish-implementation-agent
**Purpose:** Performance optimization ONLY (prevents scope creep)

**Specialization:**
- Performance profiling and optimization
- Bundle size reduction
- Load time improvements
- Memory optimization
- **Boundary:** CANNOT add features, CANNOT change functionality, tests must stay green

**TDD Workflow:**
- RED: Baseline performance metrics (not failing tests)
- GREEN: Apply optimizations (memoization, lazy loading, bundle splitting)
- REFACTOR: Fine-tune while keeping tests green

**Tools:**
- `Read`, `Write`, `Edit`, `MultiEdit`, `Glob`, `Grep`, `Bash`, `LS`
- `mcp__task-master__get_task`, `mcp__task-master__set_task_status`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls → Read current_task.json + task file
- ✅ Add DAIC mode checkpoint
- ✅ Emphasize "optimization ONLY" boundary
- ✅ Update completion reporting with metrics
- ✅ Add human confirmation requirement

**Integration Phase:** Phase 4
**Status:** Not started
**Priority:** High (critical for preventing scope creep)
**Complexity:** Medium

---

## Validation Agents (3)

### @tdd-validation-agent
**Purpose:** Actual test execution and validation before task completion

**Validation Process:**
1. Run `npm test` (actual execution, not self-reported)
2. Run `npm run build`
3. Run `npm run typecheck` (if TypeScript)
4. Check for failures
5. Block completion if any fail
6. Generate remediation tasks if needed

**Tools:**
- `Read`, `Bash`, `Grep`, `LS`, `Glob`
- `mcp__task-master__get_task`, `mcp__task-master__set_task_status`
- `mcp__ide__getDiagnostics`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls → Read current_task.json + task file
- ✅ Make test execution project-agnostic (detect test framework)
- ✅ Integration with task completion workflow
- ✅ Update remediation task generation

**Integration Phase:** Phase 3
**Status:** Not started
**Priority:** Critical
**Complexity:** Medium

---

### @enhanced-quality-gate
**Purpose:** Multi-faceted quality validation (security, performance, accessibility)

**Validation Areas:**
1. **Security:** Exposed secrets, unsafe patterns, vulnerabilities
2. **Performance:** Bundle sizes, load times, memory usage
3. **Accessibility:** WCAG 2.1 AA compliance, semantic HTML, ARIA
4. **Build:** All build targets succeed

**Tools:**
- `Read`, `Grep`, `Bash`, `LS`, `Glob`
- `mcp__task-master__get_task`
- `mcp__ide__getDiagnostics`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls → Read current_task.json + task file
- ✅ Add security scanning patterns
- ✅ Add performance validation
- ✅ Add accessibility checks
- ✅ Binary PASS/FAIL decision logic

**Integration Phase:** Phase 3
**Status:** Not started
**Priority:** High
**Complexity:** High

---

### @completion-gate
**Purpose:** Final validation that all acceptance criteria are met

**Validation Process:**
1. Load task acceptance criteria
2. Validate all deliverables exist
3. Check implementation quality
4. Review documentation completeness
5. Binary decision: COMPLETE or INCOMPLETE
6. Block if incomplete, route to fix agents

**Tools:**
- `Read`, `Grep`, `LS`, `Bash`
- `mcp__task-master__get_task`, `mcp__task-master__set_task_status`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls → Read current_task.json + task file
- ✅ Parse acceptance criteria from task file
- ✅ Add deliverable checking logic
- ✅ Integration with task completion protocol

**Integration Phase:** Phase 3
**Status:** Not started
**Priority:** Medium
**Complexity:** Medium

---

## Supporting Infrastructure (2)

### @hook-integration-agent (optional)
**Purpose:** Sets up hook system for TDD validation and quality gates

**What it does:**
- Creates hook scripts (tdd-validation.py, quality-gate.py, etc.)
- Configures `.claude/settings.json` with new hooks
- Sets up PreToolUse and PostToolUse event bindings
- Implements validation workflows

**Tools:**
- `Read`, `Write`, `Edit`, `MultiEdit`, `Bash`, `Glob`, `Grep`
- `mcp__task-master__get_task`, `mcp__task-master__set_task_status`

**Adaptations Needed:**
- ✅ Remove TaskMaster calls
- ✅ Adapt to cc-sessions hook structure
- ✅ Create cc-sessions-specific hooks
- ✅ Update settings.json format

**Integration Phase:** Phase 3 (if needed) or Manual
**Status:** Not started
**Priority:** Low (might do manually)
**Complexity:** Medium

---

### Routing Logic (required)
**Purpose:** Route to correct specialist based on task type

**Options:**
- **Option A:** Dedicated @routing-agent or @task-orchestrator
- **Option B:** Simple routing logic in DAIC hooks
- **Option C:** Claude analyzes + asks user (RECOMMENDED)

**Recommended Approach (Option C):**
1. User says "go ahead" (implementation mode unlocked)
2. Claude reads current task
3. Claude analyzes task type (UI vs backend vs setup vs tests vs performance)
4. Claude ASKS user:
   ```
   "This looks like [UI/backend/setup/testing/performance] work.

   Should I:
   1. Use [specialist-name] (TDD enforced, specialized workflow)
   2. Use general implementation (no specialist)

   Which would you prefer?"
   ```
5. User confirms choice
6. Proceed with selected approach

**Adaptations Needed:**
- ✅ Task type analysis logic
- ✅ User confirmation prompt templates
- ✅ Specialist selection based on task type
- ✅ Fallback to general implementation

**Integration Phase:** Phase 2
**Status:** Not started
**Priority:** Critical
**Complexity:** Low-Medium

---

## Agents NOT Being Integrated

### TaskMaster-Specific (skipped)
- `@prd-parser-agent` - Parses PRD into TaskMaster tasks (we create tasks manually)
- `@task-generator-agent` - Generates TaskMaster task structure (we use file-based tasks)

### Meta/System Agents (skipped or manual)
- `@behavioral-transformation-agent` - Sets up collective system (we already have DAIC)
- `@van-maintenance-agent` - Maintains agent documentation (manual for now)
- `@dynamic-agent-creator` - Creates agents on demand (not needed yet)
- `@metrics-collection-agent` - Tracks effectiveness (Phase 5 or later)

### Workflow/Coordination (using simpler approach)
- `@task-orchestrator` - Central coordination hub (using human-confirmed routing instead)
- `@routing-agent` - Auto-routing (using human confirmation instead)
- `@workflow-agent` - Multi-agent workflows (not needed for now)
- `@task-executor` - Task execution wrapper (not needed)
- `@enhanced-project-manager-agent` - Project management (not needed)

---

## Integration Summary

**Total agents to integrate:** 10
- Research: 1 agent
- Implementation: 5 agents
- Validation: 3 agents
- Routing: 1 solution (human-confirmed routing)

**Current cc-sessions agents:** 5
- context-gathering
- logging
- code-review
- context-refinement
- service-documentation

**Post-integration total:** ~15 agents

**Key principle:** Each agent adds control and discipline, not complexity.

---

## Status Tracking

### Phase 1 (Research)
- [ ] @research-agent - Not started

### Phase 2 (Proof of Concept)
- [ ] @feature-implementation-agent - Not started
- [ ] Routing logic - Not started

### Phase 3 (Validation)
- [ ] @tdd-validation-agent - Not started
- [ ] @enhanced-quality-gate - Not started
- [ ] @completion-gate - Not started

### Phase 4 (Full Suite)
- [ ] @component-implementation-agent - Not started
- [ ] @infrastructure-implementation-agent - Not started
- [ ] @testing-implementation-agent - Not started
- [ ] @polish-implementation-agent - Not started

### Phase 5 (Enhancements)
- [ ] Structured discussion output - Not started
- [ ] Test runner abstraction - Not started
- [ ] Success ceremony - Not started
- [ ] Metrics collection (optional) - Not started

---

Last Updated: 2025-01-03

===== decisions.md =====
# Decision Log - Integration Project

## Overview

This document tracks all major decisions made during the integration of claude-code-sub-agent-collective into cc-sessions. Each decision includes rationale, alternatives considered, and consequences.

---

## Architecture Decisions

### D1: Adopt Specialized Agents Approach

**Date:** 2025-01-03

**Decision:** Integrate specialized implementation agents from claude-code-collective into cc-sessions

**Context:**
- cc-sessions currently has Claude doing all implementation work
- claude-code-collective has 5 specialized implementation agents
- Initial analysis suggested avoiding "too many agents"

**Rationale:**
- Specialized agents = specialized instructions for Claude, not separate systems
- More agents = more control and discipline, not complexity
- Each specialist adds specific value (UI vs backend vs setup vs tests vs performance)
- User explicitly requested all 5 implementation + 3 validation + 1 research agents

**Alternatives Considered:**
1. ❌ Extract only patterns, no agents - User feedback: "we can't do that without their agents"
2. ❌ Use only 1-2 specialists - Doesn't solve scope creep (e.g., "optimization" needs polish-agent)
3. ✅ Adopt all specialists with clear boundaries

**Consequences:**
- ✅ Better quality enforcement (TDD, boundaries, validation)
- ✅ Prevents scope creep (each agent has ONE job)
- ✅ Clearer user experience (know what each specialist does)
- ⚠️ More agents to maintain (10 vs current 5)
- ⚠️ User needs to understand when to use which

**Status:** Approved by user

---

### D2: Human-Confirmed Routing

**Date:** 2025-01-03

**Decision:** Never auto-route to specialists. Always ask user to confirm specialist selection.

**Context:**
- claude-code-collective uses @task-orchestrator for auto-routing
- cc-sessions values user control and transparency
- External AI reviewer suggested human-confirmed routing

**Rationale:**
- Prevents misclassification (UI vs backend confusion)
- Maintains DAIC user control philosophy
- Educational for users (learn what specialists do)
- Transparent (user knows exactly what will happen)
- Fallback always available (general implementation)

**Alternatives Considered:**
1. ❌ Auto-route based on task analysis - Too opaque, could misclassify
2. ❌ User always picks specialist manually - Too much cognitive load
3. ✅ Claude suggests, user confirms - Best balance

**Implementation:**
```
Claude analyzes task → Suggests specialist → User confirms → Proceed
```

**Consequences:**
- ✅ User always in control
- ✅ No surprises from wrong specialist
- ✅ Users learn specialist capabilities
- ⚠️ Adds one confirmation step to workflow
- ⚠️ Could feel repetitive (addressed in Q6)

**Status:** Approved

---

### D3: File-Based Task Management (Not TaskMaster)

**Date:** 2025-01-03

**Decision:** Replace all TaskMaster MCP calls with file-based task reading

**Context:**
- claude-code-collective heavily uses TaskMaster MCP (external service)
- cc-sessions uses file-based tasks (sessions/tasks/*.md)
- TaskMaster provides database, APIs, structured task management
- cc-sessions is simpler, file-based, git-integrated

**Rationale:**
- cc-sessions already has working file-based task system
- Don't want external service dependencies
- Files are portable, transparent, git-friendly
- Current task state in .claude/state/current_task.json works well

**Adaptation Pattern:**
```javascript
// BEFORE (their code):
mcp__task-master__get_task --id=1.2

// AFTER (cc-sessions):
const currentTask = Read('.claude/state/current_task.json');
const taskFile = Read(`sessions/tasks/${currentTask.task}.md`);
```

**Alternatives Considered:**
1. ❌ Adopt TaskMaster MCP - Adds external dependency
2. ❌ Build TaskMaster-like system - Overengineering
3. ✅ Adapt to file-based - Keeps cc-sessions simple

**Consequences:**
- ✅ No new dependencies
- ✅ Maintains cc-sessions simplicity
- ✅ Git integration preserved
- ⚠️ Every agent needs adaptation (documented in adaptation-guide.md)

**Status:** Approved

---

### D4: DAIC Mode Checkpoints in All Implementation Agents

**Date:** 2025-01-03

**Decision:** Every implementation specialist must check DAIC mode before proceeding

**Context:**
- cc-sessions has strict DAIC phases (discussion vs implementation)
- Hooks block tools in discussion mode
- Need double protection against DAIC violations

**Rationale:**
- Defense in depth (hooks + agent logic)
- Clear error messages when specialist used incorrectly
- Even if routing fails, specialists refuse to run
- Maintains DAIC integrity

**Checkpoint Pattern:**
```javascript
// Step 1: Check DAIC mode
const daicState = Read('.claude/state/daic-mode.json');
const mode = JSON.parse(daicState).mode;

if (mode !== "implementation") {
    return `❌ CANNOT PROCEED

    This specialist can only run in implementation mode.
    Current mode: ${mode}

    User must approve implementation first.`;
}

// Step 2: Proceed with TDD workflow
```

**Alternatives Considered:**
1. ❌ Trust hooks only - Could have edge cases
2. ❌ Trust routing only - Could misfire
3. ✅ Double validation - Hooks + agent checks

**Consequences:**
- ✅ Cannot accidentally violate DAIC
- ✅ Clear error messages
- ✅ Agents enforce their own constraints
- ⚠️ Every agent needs checkpoint (boilerplate)

**Status:** Approved, documented in adaptation-guide.md

---

## Integration Strategy Decisions

### D5: Phased Rollout (5 Phases)

**Date:** 2025-01-03

**Decision:** Implement integration in 5 phases over 6 weeks

**Phases:**
1. **Phase 1 (Week 1-2):** Research agent + Context7 integration
2. **Phase 2 (Week 2-3):** Single specialist proof of concept (feature-implementation-agent)
3. **Phase 3 (Week 3-4):** Validation gates (TDD, quality, completion)
4. **Phase 4 (Week 4-6):** Full specialist suite (all 5 implementation agents)
5. **Phase 5 (Week 6+):** Enhancements (success ceremony, multi-language, metrics)

**Rationale:**
- Prove value incrementally (research → implementation → validation → full suite)
- Each phase builds on previous
- Can stop/pivot if approach doesn't work
- User can start benefiting from Phase 1 while we build Phase 2

**Alternatives Considered:**
1. ❌ All at once - Too risky, no validation
2. ❌ Research only - Doesn't prove specialists work
3. ✅ Incremental phases - De-risks integration

**Consequences:**
- ✅ Lower risk
- ✅ Early value delivery
- ✅ Can adjust based on learnings
- ⚠️ Longer timeline to full completion

**Status:** Approved in integration-plan.md

---

### D6: Keep TDD Structure Exactly

**Date:** 2025-01-03

**Decision:** Preserve TDD workflow from claude-code-collective without modification

**Context:**
- Their TDD workflow: RED (max 5 tests) → GREEN (minimal code) → REFACTOR
- Well-tested approach in their system
- Core value proposition of specialists

**Rationale:**
- Don't fix what isn't broken
- TDD discipline is THE point of specialists
- "Max 5 initial tests" prevents over-engineering
- Their workflow is proven

**What We're Keeping:**
- RED-GREEN-REFACTOR structure
- Max 5 initial tests guideline
- Specialist boundaries (UI can't do backend)
- Completion reporting format
- Test-first enforcement

**What We're Changing:**
- Task loading (TaskMaster → files)
- Research integration (add Memory Bank)
- Mode enforcement (add DAIC checkpoint)
- File paths (update to cc-sessions structure)

**Alternatives Considered:**
1. ❌ Relax TDD rules - Defeats purpose
2. ❌ Make TDD optional - Specialists exist FOR TDD
3. ✅ Keep TDD strict - That's their value

**Consequences:**
- ✅ Quality enforcement works
- ✅ Users get proven workflow
- ✅ Less risk in adaptation
- ⚠️ Users must accept TDD discipline

**Status:** Approved

---

## Technical Decisions

### D7: Context7 as Optional Enhancement

**Date:** 2025-01-03

**Decision:** Make Context7 MCP optional, with graceful fallback

**Context:**
- Research agent uses Context7 for current documentation
- Not all users will have Context7 configured
- Memory Bank MCP already provides persistent context

**Rationale:**
- Don't force external dependencies
- Research agent can use WebSearch/WebFetch as fallback
- Memory Bank provides project-specific knowledge
- Context7 enhances but isn't required

**Implementation:**
```javascript
// Research agent logic:
if (context7Available()) {
    const docs = queryContext7(library);
} else {
    const docs = webSearch(library + " documentation");
}
// Cache results to sessions/research/ either way
```

**Alternatives Considered:**
1. ❌ Require Context7 - Forces setup, blocks users
2. ❌ Remove Context7 - Loses valuable capability
3. ✅ Optional with fallback - Best of both worlds

**Consequences:**
- ✅ Works for all users
- ✅ Enhanced for Context7 users
- ✅ No forced dependencies
- ⚠️ Need fallback logic in research agent

**Status:** Approved

---

### D8: Research Cache Location

**Date:** 2025-01-03

**Decision:** Global research cache at `sessions/research/`

**Context:**
- Their system: `.taskmaster/docs/research/`
- Need cc-sessions equivalent
- Per-task vs global cache decision

**Rationale:**
- Research findings often apply to multiple tasks
- Global cache reduces redundant queries
- Tasks can reference shared research
- Simpler than per-task folders

**Structure:**
```
sessions/research/
  ├── 2025-01-03_react-hooks.md
  ├── 2025-01-03_auth-patterns.md
  └── 2025-01-04_testing-strategies.md
```

**Alternatives Considered:**
1. ❌ Per-task research - Duplication, harder to share
2. ❌ No caching - Repeated queries
3. ✅ Global cache - Shareable, efficient

**Consequences:**
- ✅ Research reused across tasks
- ✅ Simple structure
- ✅ Easy to find findings
- ⚠️ Could accumulate files (cleanup needed)

**Status:** Approved in adaptation-guide.md

---

### D9: Agent Naming Convention

**Date:** 2025-01-03

**Decision:** Keep specialist names from source, adapt to cc-sessions style (no @ prefix)

**Context:**
- Their naming: `@component-implementation-agent`
- cc-sessions style: `context-gathering` (no @)
- Need consistency

**Naming Decisions:**
```
Their name                           → cc-sessions name
@component-implementation-agent      → component-implementation
@feature-implementation-agent        → feature-implementation
@infrastructure-implementation-agent → infrastructure-implementation
@testing-implementation-agent        → testing-implementation
@polish-implementation-agent         → polish-implementation
@research-agent                      → research-gathering
@tdd-validation-agent               → tdd-validation
@enhanced-quality-gate              → quality-gate
@completion-gate                    → completion-validation
```

**Rationale:**
- Remove @ prefix (cc-sessions doesn't use it)
- Keep descriptive names (clear what they do)
- Maintain consistency with existing agents
- Easy to reference in documentation

**Consequences:**
- ✅ Consistent with cc-sessions
- ✅ Clear, descriptive names
- ✅ Easy to document
- ⚠️ Different from source (document mapping)

**Status:** Approved

---

## User Experience Decisions

### D10: Fallback to General Implementation Always Available

**Date:** 2025-01-03

**Decision:** Users can always choose general implementation instead of specialist

**Context:**
- Specialists enforce TDD and boundaries
- Some tasks might not fit specialists
- Users might want flexibility

**Rationale:**
- User control is paramount
- Specialists are OPTIONAL discipline
- Quick fixes don't need TDD overhead
- Edge cases need escape hatch

**Routing Example:**
```
Claude: "This looks like UI work.

Should I:
1. Use component-implementation specialist (TDD enforced)
2. Use general implementation (flexible)

Which would you prefer?"
```

**Alternatives Considered:**
1. ❌ Force specialists always - Too rigid
2. ❌ No specialists option - Loses value
3. ✅ Always offer both - User decides

**Consequences:**
- ✅ User always has choice
- ✅ Flexibility for edge cases
- ✅ No forced workflows
- ⚠️ Users might avoid specialists (track adoption)

**Status:** Approved in routing-strategy.md

---

### D11: File Naming Convention (Lowercase)

**Date:** 2025-01-03

**Decision:** Use lowercase with hyphens for all planning documents

**Context:**
- Initial docs used ALL CAPS (INTEGRATION-PLAN.md)
- User feedback: "Do not use all caps lock for filing naming please. Keep it normal."

**Standard:**
```
✅ integration-plan.md
✅ routing-strategy.md
✅ agent-inventory.md

❌ INTEGRATION-PLAN.md
❌ ROUTING-STRATEGY.md
❌ AGENT-INVENTORY.md
```

**Rationale:**
- User preference
- Easier to read
- Consistent with existing cc-sessions docs

**Consequences:**
- ✅ Better readability
- ✅ User satisfaction
- ✅ Consistency

**Status:** Approved and implemented

---

## Scope Decisions

### D12: Agents NOT Being Integrated

**Date:** 2025-01-03

**Decision:** Explicitly exclude certain agents as not applicable to cc-sessions

**Excluded Categories:**

1. **TaskMaster-Specific Agents:**
   - `@prd-parser-agent` - Creates TaskMaster tasks (we create tasks manually)
   - `@task-generator-agent` - TaskMaster task structure (we use files)

2. **Meta/System Agents:**
   - `@behavioral-transformation-agent` - Sets up collective system (we have DAIC)
   - `@van-maintenance-agent` - Maintains agent docs (manual for now)
   - `@dynamic-agent-creator` - Creates agents on demand (not needed yet)
   - `@metrics-collection-agent` - Tracks effectiveness (Phase 5 or later)

3. **Coordination Agents:**
   - `@task-orchestrator` - Central hub (using human-confirmed routing)
   - `@routing-agent` - Auto-routing (using human confirmation)
   - `@workflow-agent` - Multi-agent workflows (not needed for now)
   - `@task-executor` - Execution wrapper (not needed)
   - `@enhanced-project-manager-agent` - Project management (not needed)

**Rationale:**
- Different architecture (file-based vs TaskMaster)
- Different coordination model (human-confirmed vs hub-and-spoke)
- Keep cc-sessions lean and focused

**Total Integration:**
- ✅ 1 research agent
- ✅ 5 implementation specialists
- ✅ 3 validation gates
- ✅ 1 routing solution (human-confirmed, not agent)
- ❌ ~20 agents excluded as not applicable

**Status:** Approved in agent-inventory.md

---

## Process Decisions

### D13: Documentation Structure

**Date:** 2025-01-03

**Decision:** Create comprehensive planning documentation before implementation

**Documentation Created:**
- `readme.md` - Project overview
- `integration-plan.md` - Overall strategy and phases
- `agent-inventory.md` - Complete catalog of agents
- `adaptation-guide.md` - Step-by-step adaptation instructions
- `routing-strategy.md` - Routing logic specification
- `questions.md` - Open questions tracker
- `decisions.md` - This document

**Rationale:**
- User explicitly requested: "create more planning docs and integrate them in that folder, so we can know how to do the project"
- Reduces risk through thorough planning
- Creates reference for implementation
- Documents decisions and rationale

**Consequences:**
- ✅ Clear roadmap for integration
- ✅ Documented decision rationale
- ✅ Easy to onboard others
- ⚠️ More upfront time before coding

**Status:** Approved by user

---

## Next Decisions Needed

### Immediate (Before Phase 1)

1. **Q3: Context7 MCP configuration** - How to set up in sessions-config.json
2. **Q14: Phase 1 scope** - Memory Bank + Context7 integration approach

### Before Phase 2

3. **Q6: Routing confirmation frequency** - Every time vs learned preferences
4. **Q8: TDD enforcement strictness** - Strict vs configurable

### Before Phase 3

5. **Q2: Test runner abstraction** - npm only vs multi-language
6. **Q5: Validation gate ordering** - Sequential vs parallel vs conditional

### Phase 5+

7. **Q9: Success ceremony** - Automated celebration on completion
8. **Q10: Multi-language support** - When to expand beyond npm/Node.js
9. **Q11: Metrics collection** - Should we track specialist effectiveness?

---

## Decision Template

**For adding new decisions:**

### D[NUMBER]: [Decision Title]

**Date:** YYYY-MM-DD

**Decision:** [One sentence statement of decision]

**Context:**
- [Background information]
- [Why this decision was needed]
- [Current state before decision]

**Rationale:**
- [Why this decision was made]
- [Key factors considered]
- [Expected benefits]

**Alternatives Considered:**
1. ❌ [Alternative 1] - [Why rejected]
2. ❌ [Alternative 2] - [Why rejected]
3. ✅ [Chosen option] - [Why chosen]

**Consequences:**
- ✅ [Positive consequence]
- ✅ [Positive consequence]
- ⚠️ [Trade-off or risk]

**Status:** Approved/Pending/Implemented

---

Last Updated: 2025-01-03

===== integration-plan.md =====
# Integration Plan: claude-code-collective → cc-sessions

## Executive Summary

Integrate specialized agents from claude-code-sub-agent-collective to add:
1. **Research-backed planning** during discussion phase
2. **Specialized TDD implementation** during implementation phase
3. **Multi-gate validation** before task completion

**Total agents to integrate:** ~10-12 agents
**Current cc-sessions agents:** 5
**Post-integration:** ~15-17 agents

## Core Philosophy

**Maintain cc-sessions principles:**
- ✅ DAIC phases remain (discussion → implementation)
- ✅ Human-in-the-loop control preserved
- ✅ User must approve before implementation
- ✅ File-based tasks (not TaskMaster)
- ✅ Memory Bank integration maintained

**Add from collective:**
- ✅ Research agent for current documentation (Context7)
- ✅ Specialized implementation agents (TDD enforced)
- ✅ Quality validation gates (actual test execution)

## Agents Being Integrated

### Research Enhancement (Discussion Phase)
**@research-agent** - Context7 integration
- Queries current documentation
- Caches findings per task
- Works WITH Memory Bank (complementary)

### Implementation Specialists (Implementation Phase)

**@component-implementation-agent** - UI only
- React, HTML, CSS, styling, interactions
- TDD: UI tests first (max 5 initially)
- Boundary: Cannot do backend work

**@feature-implementation-agent** - Backend only
- APIs, business logic, data services, state management
- TDD: Logic tests first (max 5 initially)
- Boundary: Cannot do UI work

**@infrastructure-implementation-agent** - Setup only
- Build config, dependencies, environment, tooling
- TDD: Config validation tests
- Boundary: Cannot add features

**@testing-implementation-agent** - Tests only
- Adding tests to existing code
- Boundary: Cannot modify implementation

**@polish-implementation-agent** - Performance ONLY
- Optimization, bundle size, performance
- Boundary: Cannot add features, cannot change functionality
- Critical: Prevents "optimization" scope creep

### Validation Gates (Completion Phase)

**@tdd-validation-agent**
- Runs: npm test, npm run build
- Blocks completion if failing
- Generates remediation tasks

**@enhanced-quality-gate**
- Security scanning (exposed secrets, unsafe patterns)
- Performance validation (bundle sizes, load times)
- Accessibility compliance (WCAG 2.1 AA)

**@completion-gate**
- Validates all acceptance criteria met
- Binary COMPLETE/INCOMPLETE decision
- Final gate before task done

## Key Refinements from External Review

### 1. Human-Confirmed Routing ⭐
**Never auto-route without confirmation:**

```
User: "go ahead"
    ↓
Claude analyzes task type
    ↓
Claude ASKS: "This looks like UI work. Should I:
  1. Use component-implementation specialist (TDD enforced)
  2. Use general implementation (no specialist)

Which would you prefer?"
    ↓
User confirms choice
    ↓
Proceed with selected path
```

**Why:**
- Transparency - user knows what will happen
- Prevents misclassification
- Maintains DAIC user control
- Educational - users learn what specialists do

### 2. Mode-Aware Checkpoint ⭐
**Every specialist starts with:**

```markdown
## DAIC Mode Check (MANDATORY FIRST STEP):
1. Read .claude/state/daic-mode.json
2. If mode != "implementation" → REFUSE to proceed
3. If mode == "implementation" → Continue with TDD workflow
```

**Why:**
- Double protection (hooks + agent logic)
- Even if routing fails, specialists won't break DAIC
- Clear error messages

### 3. Fallback Path ⭐
**Always offer non-specialist option**

Specialists are OPTIONAL. User can choose general implementation if:
- Task doesn't fit specialists
- User wants flexibility
- Quick/simple changes

## Phased Implementation

### Phase 1: Research Enhancement (Week 1-2)
**Goal:** Prove research improves planning

**Tasks:**
- Adapt @research-agent to cc-sessions
- Remove TaskMaster dependencies
- Add Context7 MCP integration
- Wire into discussion mode (DAIC hooks)
- Test Memory Bank + Context7 complementary use

**Success criteria:**
- Research agent works in discussion mode
- Context7 queries succeed
- Findings cached to sessions/research/
- Memory Bank integration preserved

### Phase 2: Single Specialist Proof (Week 2-3)
**Goal:** Prove specialist approach works

**Tasks:**
- Adapt @feature-implementation-agent
- Remove TaskMaster dependencies
- Add DAIC mode checkpoint
- Implement human-confirmed routing
- Test TDD enforcement

**Success criteria:**
- One specialist works end-to-end
- TDD workflow enforced (RED-GREEN-REFACTOR)
- Mode checkpoint prevents discussion-mode usage
- Human confirmation feels natural

### Phase 3: Validation Gates (Week 3-4)
**Goal:** Add quality enforcement

**Tasks:**
- Adapt @tdd-validation-agent
- Adapt @enhanced-quality-gate
- Adapt @completion-gate
- Create /validate command (optional)
- Test actual test execution

**Success criteria:**
- Gates catch actual issues
- Test execution works
- Security/performance/accessibility scans run

### Phase 4: Full Specialist Suite (Week 4-6)
**Goal:** Complete implementation coverage

**Tasks:**
- Adapt remaining 4 implementation agents
- Expand routing logic for all types
- Test specialist boundaries
- Refine based on usage

**Success criteria:**
- All 5 specialists work
- Routing picks correct specialist
- Boundaries enforced

### Phase 5: Enhancements (Week 6+)
**Goal:** Polish the experience

**Tasks:**
- Structured discussion output template
- Test runner abstraction (Python, Go, Rust support)
- Success ceremony (auto-log completion reports)
- Wire /validate into DAIC Check step

## Adaptation Requirements

### 1. Remove TaskMaster MCP Calls

**Their agents use:**
```javascript
mcp__task-master__get_task --id=1.2
```

**Adapt to:**
```javascript
// Get current task
const currentTask = Read('.claude/state/current_task.json');

// Load task file
const taskFile = Read(`sessions/tasks/${currentTask.task}.md`);
```

### 2. Add Context7 MCP

**Add to sessions-config.json:**
```json
{
  "context7": {
    "enabled": true,
    "cache_dir": "sessions/research/"
  }
}
```

### 3. Update DAIC Hooks

Allow research agent in discussion mode, implementation agents only in implementation mode.

### 4. Add Routing Logic

Human-confirmed routing (Claude asks, user chooses).

## Success Metrics

- Specialists stay in scope (0 boundary violations)
- TDD compliance (100% of implementations have tests)
- Validation catches issues
- Research improves plans

## Next Steps

1. Review this plan
2. Decide on open questions
3. Start Phase 1 - research agent
4. Iterate based on learnings

---

**Status:** Planning
**Last Updated:** 2025-01-03

===== phase-1-research-agent.md =====
# Phase 1: Research Agent Integration

## Overview

**Goal:** Prove research-backed planning improves discussion phase quality

**Duration:** Week 1-2

**Deliverable:** Working research agent that queries Context7, caches findings, and integrates with Memory Bank

---

## Objectives

### Primary Objectives

1. Adapt @research-agent to cc-sessions architecture
2. Remove TaskMaster dependencies
3. Integrate Context7 MCP for current documentation
4. Wire into DAIC discussion mode
5. Test Memory Bank + Context7 complementary use

### Success Criteria

- ✅ Research agent runs successfully in discussion mode
- ✅ Context7 queries return relevant documentation
- ✅ Findings cached to `sessions/research/`
- ✅ Memory Bank integration preserved
- ✅ Graceful fallback when Context7 unavailable
- ✅ Research improves task context quality

---

## Source Agent Analysis

### Their @research-agent

**File:** `templates/agents/research-agent.md` (172 lines)

**What it does:**
- Queries Context7 MCP for library documentation
- Extracts working code examples
- Caches findings to `.taskmaster/docs/research/`
- Provides research-backed planning recommendations

**Tools used:**
- `mcp__context7__resolve-library-id`
- `mcp__context7__get-library-docs`
- `Read`, `Write`, `Grep`, `LS`
- `WebSearch`, `WebFetch` (fallback)
- `mcp__task-master__get_task` (needs removal)

**Workflow:**
1. Load task from TaskMaster
2. Identify technologies mentioned in task
3. Query Context7 for each technology
4. Extract code examples and best practices
5. Cache findings with timestamp
6. Return research summary

---

## Adaptation Requirements

### 1. Remove TaskMaster Dependency

**BEFORE (their code):**
```javascript
// Load task
const task = mcp__task-master__get_task(taskId);
const technologies = task.tech_stack || [];
```

**AFTER (cc-sessions):**
```javascript
// Load current task
const currentTask = Read('.claude/state/current_task.json');
const taskContent = Read(`sessions/tasks/${currentTask.task}.md`);

// Parse task for technologies
const technologies = extractTechnologies(taskContent);
// Look in: Success Criteria, Context, Task description
```

### 2. Update Cache Location

**BEFORE:**
```javascript
// Cache research
Write('.taskmaster/docs/research/${timestamp}_${topic}.md', research);
```

**AFTER:**
```javascript
// Cache to sessions/research/
Write('sessions/research/${timestamp}_${topic}.md', research);
```

### 3. Add Memory Bank Integration

**NEW (cc-sessions enhancement):**
```javascript
// Check Memory Bank for existing project knowledge
if (memoryBankAvailable()) {
    const projectContext = queryMemoryBank([
        'architectural-insights',
        'technology-decisions',
        'implementation-patterns'
    ]);
    // Combine with Context7 findings
}
```

### 4. Add DAIC Mode Awareness

**NEW (discussion mode requirement):**
```markdown
## Mode Check
This agent runs in DISCUSSION MODE only.

1. Verify mode: Read('.claude/state/daic-mode.json')
2. If implementation mode → suggest running before discussion
3. If discussion mode → proceed with research
```

### 5. Graceful Context7 Fallback

**NEW (optional MCP handling):**
```javascript
// Try Context7 first
if (context7Available()) {
    const docs = mcp__context7__get-library-docs(library);
} else {
    // Fallback to web search
    const docs = WebSearch(`${library} documentation latest`);
    const content = WebFetch(docs[0].url);
}

// Cache either way
Write(`sessions/research/${timestamp}_${library}.md`, docs);
```

---

## Implementation Steps

### Step 1: Copy and Adapt Agent File

```bash
# Copy from their repo
cp claude-code-sub-agent-collective/templates/agents/research-agent.md \
   TestProject/.claude/agents/research-gathering.md
```

**Adaptations:**
1. Update frontmatter:
   ```yaml
   ---
   name: research-gathering
   description: Context7 integration for current documentation during discussion phase
   tools: mcp__context7__resolve-library-id, mcp__context7__get-library-docs, Read, Write, Grep, LS, WebSearch, WebFetch
   color: cyan
   ---
   ```

2. Remove TaskMaster calls
3. Add file-based task loading
4. Update cache paths
5. Add Memory Bank integration
6. Add Context7 fallback logic

### Step 2: Create Research Cache Directory

```bash
mkdir -p sessions/research
```

### Step 3: Update Sessions Config

**Edit `sessions/sessions-config.json`:**
```json
{
  "context7": {
    "enabled": true,
    "cache_dir": "sessions/research/",
    "fallback_to_websearch": true
  }
}
```

### Step 4: Test Context7 Integration

**Test 1: Context7 Available**
```
User: "Research React hooks best practices"
→ Agent queries Context7
→ Caches to sessions/research/2025-01-03_react-hooks.md
→ Returns summary with code examples
```

**Test 2: Context7 Unavailable**
```
User: "Research React hooks best practices"
→ Agent detects no Context7
→ Falls back to WebSearch
→ Caches to sessions/research/2025-01-03_react-hooks.md
→ Returns summary with code examples
```

**Test 3: Memory Bank Integration**
```
User: "Research authentication patterns"
→ Agent checks Memory Bank for existing auth knowledge
→ Combines with Context7/web search
→ Returns comprehensive research
```

### Step 5: Wire into Discussion Mode

**Option A: Manual Invocation**
```
User (in discussion mode): "Research the best way to implement X"
Claude: "I'll use the research-gathering agent to find current best practices."
→ Invokes agent
→ Returns research summary
```

**Option B: Automatic Suggestion**
```
User: "I need to implement authentication"
Claude: "Would you like me to research current authentication best practices before we plan the approach?"
→ If yes, invoke research agent
```

### Step 6: Validate Integration

**Checklist:**
- [ ] Agent reads current task correctly
- [ ] Context7 queries work (if available)
- [ ] WebSearch fallback works
- [ ] Research cached to sessions/research/
- [ ] Memory Bank integration works
- [ ] Agent only runs in discussion mode
- [ ] Research improves task planning

---

## Testing Plan

### Test Scenario 1: React Component Research

**Setup:**
- Create task: `sessions/tasks/implement-login-form.md`
- Task mentions: "React", "form validation", "accessibility"

**Test:**
1. User: "Research best practices for this task"
2. Agent analyzes task
3. Identifies: React, form validation, accessibility
4. Queries Context7 for each
5. Caches findings
6. Returns summary with code examples

**Expected Outcome:**
- 3 research files created in sessions/research/
- Summary includes React hooks, validation libraries, ARIA patterns
- Code examples included

### Test Scenario 2: Backend API Research

**Setup:**
- Create task: `sessions/tasks/implement-auth-api.md`
- Task mentions: "Express", "JWT", "security"

**Test:**
1. User: "Research authentication patterns"
2. Agent analyzes task
3. Identifies: Express, JWT, security best practices
4. Queries Context7/WebSearch
5. Checks Memory Bank for existing auth patterns
6. Returns comprehensive research

**Expected Outcome:**
- Research combines Context7 docs + Memory Bank knowledge
- Security best practices highlighted
- JWT implementation examples included

### Test Scenario 3: No Context7 Fallback

**Setup:**
- Disable Context7 MCP
- Create task requiring research

**Test:**
1. User: "Research GraphQL best practices"
2. Agent detects no Context7
3. Falls back to WebSearch
4. Fetches and parses documentation
5. Caches findings

**Expected Outcome:**
- Research succeeds without Context7
- Quality comparable (might be less structured)
- No errors from missing MCP

---

## Integration with Existing Workflow

### Discussion Phase Flow (With Research)

```
User: "I need to implement user authentication"
    ↓
Claude: "Let me research current authentication best practices."
    ↓
[Invoke research-gathering agent]
    ↓
Agent returns: "Research findings cached. Summary:
- Recommended: Passport.js or Auth0
- Security: JWT with refresh tokens
- Best practices: [list]
- Code examples: [examples]"
    ↓
Claude: "Based on research, I recommend [approach].
Here's why: [reasoning based on research]

Does this align with your needs?"
    ↓
User: "Yes" / "Let's adjust..."
    ↓
[Continue discussion phase with research-backed planning]
```

### Memory Bank Synergy

**Memory Bank provides:**
- Project-specific architectural decisions
- Past implementation patterns
- Team preferences
- Existing code structure

**Research agent provides:**
- Current library documentation
- Latest best practices
- Code examples from official docs
- Security/performance patterns

**Together:**
- Memory Bank: "We use Express and prefer middleware patterns"
- Research: "Latest Express security middleware: helmet, cors, rate-limiting"
- Result: Research-backed recommendations that fit project architecture

---

## Success Metrics

### Quantitative

- **Research accuracy:** 90%+ of findings relevant to task
- **Cache hit rate:** Research reused across 30%+ of tasks
- **Context7 availability:** Graceful fallback 100% of time
- **Integration time:** Research adds <2min to discussion phase

### Qualitative

- **User feedback:** "Research improved my understanding"
- **Planning quality:** Task context more comprehensive
- **Decision quality:** Implementation choices better justified
- **Learning:** User learns best practices during discussion

---

## Risks and Mitigations

### Risk 1: Context7 Not Available

**Mitigation:**
- Graceful fallback to WebSearch + WebFetch
- Clear messaging when using fallback
- Cache both sources equally

### Risk 2: Research Overload

**Problem:** Too much research, analysis paralysis

**Mitigation:**
- Focus on 2-3 key technologies per task
- Summarize findings, don't dump raw docs
- Highlight actionable recommendations

### Risk 3: Outdated Cached Research

**Problem:** Cached findings become stale

**Mitigation:**
- Timestamp all cached research
- Offer to refresh research >7 days old
- Update cache if new version detected

### Risk 4: Memory Bank Conflicts

**Problem:** Memory Bank says one thing, Context7 says another

**Mitigation:**
- Prioritize Memory Bank for project-specific decisions
- Use Context7 for library-specific best practices
- Highlight conflicts and ask user to resolve

---

## Next Steps After Phase 1

### If Successful

1. **Document research patterns** - Create research protocol
2. **Expand to Phase 2** - Prove specialist implementation works
3. **Refine UX** - Based on user feedback
4. **Consider auto-research** - Automatically research on task creation?

### If Issues Arise

1. **Iterate on research agent** - Fix identified problems
2. **Simplify if needed** - Remove Context7 if problematic
3. **User feedback** - Understand what's not working
4. **Adjust approach** - Pivot if necessary

---

## Deliverables

### Files to Create

1. **TestProject/.claude/agents/research-gathering.md**
   - Adapted research agent
   - All TaskMaster calls removed
   - Memory Bank integration added
   - Context7 with fallback

2. **sessions/research/** (directory)
   - Research cache location
   - Initially empty
   - Populated by agent

3. **sessions/sessions-config.json** (update)
   - Add Context7 configuration
   - Enable research caching

4. **Documentation updates**
   - Update USAGE_GUIDE.md with research agent
   - Add research workflow examples
   - Document Context7 setup (optional)

### Testing Artifacts

- [ ] Test results for Scenario 1 (React)
- [ ] Test results for Scenario 2 (Backend)
- [ ] Test results for Scenario 3 (Fallback)
- [ ] User feedback notes
- [ ] Performance metrics

---

## Timeline

**Week 1:**
- Day 1-2: Adapt agent file
- Day 3-4: Test Context7 integration
- Day 5: Test Memory Bank integration
- Day 6-7: User testing and refinement

**Week 2:**
- Day 1-3: Fix issues from user testing
- Day 4-5: Documentation updates
- Day 6-7: Final validation, prepare for Phase 2

---

Last Updated: 2025-01-03

===== phase-2-single-specialist.md =====
# Phase 2: Single Specialist Proof of Concept

## Overview

**Goal:** Prove specialized implementation agents work in cc-sessions

**Duration:** Week 2-3

**Deliverable:** One fully working specialist (@feature-implementation-agent) with human-confirmed routing

---

## Objectives

### Primary Objectives

1. Adapt @feature-implementation-agent to cc-sessions
2. Remove TaskMaster dependencies completely
3. Add DAIC mode checkpoint enforcement
4. Implement human-confirmed routing
5. Prove TDD workflow enforcement works

### Success Criteria

- ✅ One specialist works end-to-end (feature-implementation-agent)
- ✅ TDD workflow enforced (RED-GREEN-REFACTOR)
- ✅ Mode checkpoint prevents discussion-mode usage
- ✅ Human confirmation feels natural
- ✅ Specialist boundaries respected (no UI work)
- ✅ Quality improves vs general implementation

---

## Why Feature Implementation Agent First?

### Reasoning

1. **Most versatile** - Handles backend, APIs, business logic (broadest use case)
2. **Clear boundaries** - Cannot do UI work (easy to validate boundary enforcement)
3. **TDD-friendly** - Logic testing is straightforward (vs UI testing complexity)
4. **Proven value** - Backend bugs are costly, TDD prevents them

### Alternative Specialists Considered

- ❌ Component agent - UI testing more complex, save for Phase 4
- ❌ Infrastructure agent - Narrower use case, less frequent
- ❌ Testing agent - Depends on existing code, not pure implementation
- ❌ Polish agent - Optimization is advanced, Phase 4
- ✅ Feature agent - Best proof of concept candidate

---

## Source Agent Analysis

### Their @feature-implementation-agent

**File:** `templates/agents/feature-implementation-agent.md` (147 lines)

**What it does:**
- Implements backend/business logic with TDD enforcement
- Specializes in: APIs, services, data processing, state management
- Enforces: Tests FIRST (max 5 initially), then minimal code to pass
- Boundaries: Cannot do UI work, setup, or optimization

**Tools used:**
- `Read`, `Write`, `Edit`, `MultiEdit`, `Glob`, `Grep`, `LS`, `Bash`
- `mcp__task-master__get_task` (needs removal)
- `mcp__task-master__set_task_status` (needs removal)

**TDD Workflow:**
1. **RED Phase:**
   - Write 5 essential tests (happy path, validation, edge case, error, data flow)
   - Expect failures (no implementation yet)

2. **GREEN Phase:**
   - Write MINIMAL code to pass tests
   - No extra features
   - Just enough to make tests green

3. **REFACTOR Phase:**
   - Error handling
   - Input validation
   - Code optimization
   - Documentation

---

## Adaptation Requirements

### 1. Remove TaskMaster Dependencies

**Pattern from adaptation-guide.md:**

```javascript
// BEFORE (their code):
const task = mcp__task-master__get_task(taskId);
const criteria = task.acceptance_criteria;
const testStrategy = task.test_strategy;

// AFTER (cc-sessions):
const currentTask = Read('.claude/state/current_task.json');
const taskContent = Read(`sessions/tasks/${currentTask.task}.md`);

// Parse task file sections
const criteria = extractSection(taskContent, '## Success Criteria');
const testStrategy = extractSection(taskContent, '## Test Strategy');
```

### 2. Add DAIC Mode Checkpoint

**Pattern from adaptation-guide.md:**

```markdown
## 🚨 CRITICAL: DAIC Mode Checkpoint (MANDATORY FIRST STEP)

Before any implementation work:

1. **Check DAIC Mode:**
   ```javascript
   const daicState = Read('.claude/state/daic-mode.json');
   const mode = JSON.parse(daicState).mode;
   ```

2. **Validate Implementation Mode:**
   ```javascript
   if (mode !== "implementation") {
       return `❌ CANNOT PROCEED

       This specialist can only run in implementation mode.
       Current mode: ${mode}

       User must:
       1. Approve implementation ("go ahead", "make it so")
       2. Wait for DAIC to unlock implementation mode
       3. Then retry specialist
       `;
   }
   ```

3. **Proceed with TDD workflow** (only if mode check passes)
```

### 3. Update File Paths

```javascript
// BEFORE:
.taskmaster/docs/research/
.taskmaster/tasks/

// AFTER:
sessions/research/
sessions/tasks/
```

### 4. Keep TDD Structure Exactly

**NO CHANGES to:**
- RED-GREEN-REFACTOR structure
- Max 5 initial tests guideline
- Specialist boundaries
- Completion reporting format

---

## Implementation Steps

### Step 1: Copy and Adapt Agent File

```bash
# Copy from their repo
cp claude-code-sub-agent-collective/templates/agents/feature-implementation-agent.md \
   TestProject/.claude/agents/feature-implementation.md
```

**Adaptations checklist:**
- [ ] Update frontmatter (name, tools, color)
- [ ] Add DAIC mode checkpoint at top
- [ ] Remove TaskMaster get_task calls
- [ ] Remove TaskMaster set_task_status calls
- [ ] Update file paths (sessions/tasks/, sessions/research/)
- [ ] Add helper functions (loadCurrentTask, extractSection)
- [ ] Keep TDD workflow unchanged
- [ ] Preserve boundary enforcement

### Step 2: Implement Human-Confirmed Routing

**Where:** Main Claude conversation (not in specialist agent)

**Flow from routing-strategy.md:**

```
User: "go ahead" / "make it so"
    ↓
DAIC switches to implementation mode
    ↓
Claude analyzes current task:
    - Reads sessions/tasks/${task}.md
    - Checks Success Criteria
    - Identifies deliverables (API? Service? Logic?)
    ↓
Claude asks:
    "This looks like backend/logic work.

    Should I:
    1. Use feature-implementation specialist (TDD enforced)
    2. Use general implementation (flexible)

    Which would you prefer?"
    ↓
User confirms: "1" or "use specialist"
    ↓
Claude invokes Task tool with feature-implementation agent
```

**Implementation:**

```javascript
// In main conversation, after implementation mode unlocked:

// 1. Load task
const currentTask = Read('.claude/state/current_task.json');
const taskContent = Read(`sessions/tasks/${currentTask.task}.md`);

// 2. Analyze task type
const criteria = extractSection(taskContent, '## Success Criteria');
const isBackendWork =
    criteria.includes('API') ||
    criteria.includes('service') ||
    criteria.includes('logic') ||
    criteria.includes('data processing') ||
    criteria.includes('state management');

// 3. Suggest specialist if backend work
if (isBackendWork) {
    prompt = `This looks like **backend/logic** work.

**Suggested approach:**
Use \`feature-implementation\` specialist which will:
- Enforce TDD (write tests FIRST, then code)
- Focus on business logic only (no UI)
- Follow RED-GREEN-REFACTOR workflow

**Alternative:**
General implementation (more flexible, no TDD enforcement)

**Your preference?**
1. Use specialist
2. General implementation`;

    // Wait for user confirmation
}
```

### Step 3: Create Routing Helper Function

**File:** `cc_sessions/hooks/shared_state.py` (add function)

```python
def suggest_specialist_routing(task_content: str) -> dict:
    """
    Analyze task and suggest appropriate specialist.

    Returns:
        {
            'suggested_specialist': 'feature-implementation' or None,
            'confidence': 'high' / 'medium' / 'low',
            'reasoning': 'why this specialist suggested'
        }
    """
    criteria_lower = task_content.lower()

    # Backend/logic indicators
    backend_keywords = ['api', 'service', 'logic', 'data processing',
                       'state management', 'business logic', 'endpoint']

    if any(keyword in criteria_lower for keyword in backend_keywords):
        return {
            'suggested_specialist': 'feature-implementation',
            'confidence': 'high',
            'reasoning': 'Task involves backend/business logic implementation'
        }

    # Add more specialist detection later

    return {
        'suggested_specialist': None,
        'confidence': 'low',
        'reasoning': 'Task type unclear'
    }
```

### Step 4: Test Boundary Enforcement

**Boundary Check in Specialist:**

```markdown
## Step 1: Boundary Validation

Before starting TDD workflow:

1. Load task: Read('sessions/tasks/${task}.md')
2. Check deliverables against specialization:

   **✅ IN SCOPE (Backend/Logic):**
   - APIs and web services
   - Business logic and data processing
   - State management
   - Data services and persistence
   - Authentication/authorization logic

   **❌ OUT OF SCOPE:**
   - UI components or React/Vue code
   - CSS or styling
   - Build configuration
   - Performance optimization (use polish-agent)
   - Test-only work (use testing-agent)

3. If out of scope:
   ```
   ❌ BOUNDARY VIOLATION

   This task requires [UI/setup/optimization] work.
   I'm the feature-implementation specialist (backend/logic only).

   Options:
   1. Use component-implementation specialist (for UI)
   2. Use infrastructure-implementation specialist (for setup)
   3. Use polish-implementation specialist (for optimization)
   4. Use general implementation (for mixed work)

   Which would you prefer?
   ```
```

### Step 5: Validate TDD Workflow

**Test RED Phase:**

```javascript
// Specialist creates 5 tests BEFORE any implementation

// Test file: tests/auth.service.test.js
describe('AuthService', () => {
    // Test 1: Happy path
    it('should authenticate valid user', async () => {
        const result = await authService.login('user@example.com', 'password123');
        expect(result).toHaveProperty('token');
        expect(result.user.email).toBe('user@example.com');
    });

    // Test 2: Validation
    it('should reject invalid email format', async () => {
        await expect(
            authService.login('invalid-email', 'password123')
        ).rejects.toThrow('Invalid email format');
    });

    // Test 3: Edge case
    it('should handle empty password', async () => {
        await expect(
            authService.login('user@example.com', '')
        ).rejects.toThrow('Password required');
    });

    // Test 4: Error handling
    it('should throw on wrong credentials', async () => {
        await expect(
            authService.login('user@example.com', 'wrong-password')
        ).rejects.toThrow('Invalid credentials');
    });

    // Test 5: Data flow
    it('should hash password before storage', async () => {
        const spy = jest.spyOn(bcrypt, 'hash');
        await authService.register('new@example.com', 'password123');
        expect(spy).toHaveBeenCalledWith('password123', expect.any(Number));
    });
});

// Run: npm test
// Expected: All 5 tests FAIL (no implementation yet)
```

**Test GREEN Phase:**

```javascript
// Specialist creates MINIMAL implementation to pass tests

// File: src/services/auth.service.js
class AuthService {
    async login(email, password) {
        // Validation (Test 2)
        if (!email.includes('@')) {
            throw new Error('Invalid email format');
        }

        // Empty password check (Test 3)
        if (!password) {
            throw new Error('Password required');
        }

        // Mock database lookup
        const user = await db.findUserByEmail(email);

        // Wrong credentials (Test 4)
        if (!user || user.password !== password) {
            throw new Error('Invalid credentials');
        }

        // Generate token (Test 1)
        const token = jwt.sign({ userId: user.id }, SECRET);

        return { token, user };
    }

    async register(email, password) {
        // Hash password (Test 5)
        const hashedPassword = await bcrypt.hash(password, 10);
        const user = await db.createUser({ email, password: hashedPassword });
        return user;
    }
}

// Run: npm test
// Expected: All 5 tests PASS
```

**Test REFACTOR Phase:**

```javascript
// Specialist improves implementation

class AuthService {
    async login(email, password) {
        // Input validation with better error messages
        this.validateEmail(email);
        this.validatePassword(password);

        const user = await this.findUser(email);
        await this.verifyPassword(password, user.password);

        const token = this.generateToken(user);

        return { token, user: this.sanitizeUser(user) };
    }

    // Private helper methods
    private validateEmail(email: string) {
        const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        if (!emailRegex.test(email)) {
            throw new Error('Invalid email format');
        }
    }

    private validatePassword(password: string) {
        if (!password || password.length < 8) {
            throw new Error('Password must be at least 8 characters');
        }
    }

    // ... more refactored methods
}

// Run: npm test
// Expected: All tests still PASS (refactoring didn't break anything)
```

---

## Testing Plan

### Test Scenario 1: Pure Backend Task

**Setup:**
```markdown
# sessions/tasks/implement-auth-service.md

## Purpose
Implement authentication service with JWT

## Success Criteria
- User login with email/password
- JWT token generation
- Password hashing with bcrypt
- Error handling for invalid credentials
- Input validation

## Test Strategy
- Unit tests for AuthService
- Integration tests for auth endpoints
- Security tests for password handling
```

**Test Flow:**
1. User: "go ahead"
2. DAIC switches to implementation mode
3. Claude analyzes task → identifies backend work
4. Claude asks: "Use feature-implementation specialist?"
5. User: "yes"
6. Claude invokes specialist
7. Specialist checks DAIC mode ✅
8. Specialist validates boundaries ✅ (pure backend)
9. Specialist follows TDD:
   - RED: 5 tests written, all fail
   - GREEN: Minimal implementation, all pass
   - REFACTOR: Improved code, tests still pass
10. Task complete with high quality

**Expected Outcome:**
- ✅ TDD enforced (tests first)
- ✅ Boundaries respected (no UI code)
- ✅ Quality code delivered
- ✅ User satisfied with process

### Test Scenario 2: Mixed UI + Backend (Boundary Test)

**Setup:**
```markdown
# sessions/tasks/implement-login-page.md

## Purpose
Implement login page with authentication

## Success Criteria
- Login form component (UI)
- Form validation
- Auth service integration (backend)
- Error display

## Test Strategy
- Component tests for UI
- Service tests for backend
```

**Test Flow:**
1. User: "go ahead"
2. Claude analyzes task → identifies MIXED work (UI + backend)
3. Claude asks:
   ```
   This task involves both UI and backend work.

   Should I:
   1. Use general implementation (handles both)
   2. Split into phases:
      - Component specialist for UI
      - Feature specialist for backend

   Which would you prefer?
   ```
4. User chooses option 2
5. Phase 1: Component specialist for UI
6. Phase 2: Feature specialist for backend

**Expected Outcome:**
- ✅ Mixed work handled correctly
- ✅ User controls workflow
- ✅ Specialists stay in scope

### Test Scenario 3: Boundary Violation (Error Handling)

**Setup:**
- Task clearly requires UI work
- User mistakenly selects feature-implementation specialist

**Test Flow:**
1. User: "use feature specialist"
2. Claude invokes feature-implementation agent
3. Agent checks DAIC mode ✅
4. Agent validates boundaries ❌ (sees UI requirements)
5. Agent refuses:
   ```
   ❌ BOUNDARY VIOLATION

   This task requires UI component implementation.
   I'm the feature-implementation specialist (backend/logic only).

   I cannot implement:
   - React components
   - CSS styling
   - User interactions

   Suggested alternatives:
   1. Use component-implementation specialist (UI work)
   2. Use general implementation (mixed work)

   Please choose different approach.
   ```
6. Claude relays refusal to user
7. User chooses component specialist

**Expected Outcome:**
- ✅ Boundary enforced
- ✅ Clear error message
- ✅ Recovery path offered
- ✅ Quality maintained (no out-of-scope work)

### Test Scenario 4: Discussion Mode Protection

**Setup:**
- User still in discussion mode
- User tries to invoke specialist

**Test Flow:**
1. User (in discussion mode): "use feature specialist"
2. Claude invokes feature-implementation agent
3. Agent checks DAIC mode
4. Agent detects mode = "discussion"
5. Agent refuses:
   ```
   ❌ CANNOT PROCEED

   This specialist can only run in implementation mode.
   Current mode: discussion

   User must:
   1. Approve implementation ("go ahead", "make it so")
   2. Wait for DAIC to unlock implementation mode
   3. Then retry specialist
   ```
6. Claude explains to user
7. User says "go ahead"
8. DAIC switches to implementation
9. Specialist now proceeds

**Expected Outcome:**
- ✅ DAIC integrity maintained
- ✅ Clear error message
- ✅ User understands workflow
- ✅ Specialist protects DAIC

---

## Success Metrics

### Quantitative

- **TDD compliance:** 100% of implementations have tests first
- **Boundary violations:** 0 (specialist refuses out-of-scope work)
- **Mode violations:** 0 (specialist refuses discussion-mode invocation)
- **Test pass rate:** 100% after GREEN phase
- **Routing accuracy:** 90%+ correct specialist suggestions

### Qualitative

- **User confidence:** "I trust the specialist to do it right"
- **Code quality:** "Tests caught bugs before they shipped"
- **Learning:** "I understand TDD better now"
- **Process:** "Routing confirmation felt natural"

---

## Risks and Mitigations

### Risk 1: User Rejects Specialist Every Time

**Problem:** User always chooses general implementation

**Mitigation:**
- Ask why (too slow? Don't understand TDD?)
- Offer to adjust workflow
- Make specialists optional (already the case)
- Track feedback, iterate

### Risk 2: TDD Feels Too Slow

**Problem:** Writing 5 tests first feels like overhead

**Mitigation:**
- Explain value: "Tests catch bugs early"
- Show time saved vs debugging later
- Offer quick mode: 3 tests minimum
- Make it clear: Specialist = quality over speed

### Risk 3: Boundary Detection Fails

**Problem:** Routing suggests wrong specialist

**Mitigation:**
- User confirms before invocation (built-in safety)
- Specialist validates boundaries (double check)
- Learn from misclassifications
- Improve detection algorithm

### Risk 4: DAIC Mode Checkpoint Annoys Users

**Problem:** "I know I'm in discussion mode, why block me?"

**Mitigation:**
- Clear error message explains WHY
- Offer quick fix: "Say 'go ahead' to proceed"
- Document DAIC benefits
- Consider user preference override (Phase 5)

---

## Next Steps After Phase 2

### If Successful

1. **Phase 3: Validation Gates** - Add TDD validation, quality gates
2. **Phase 4: Full Specialist Suite** - Add remaining 4 specialists
3. **Documentation** - Update USAGE_GUIDE.md with specialists
4. **User Training** - Create specialist usage examples

### If Issues Arise

1. **Iterate on Routing** - Improve specialist suggestion accuracy
2. **Simplify TDD** - Reduce test count if too burdensome
3. **Adjust Boundaries** - Refine what each specialist can do
4. **User Feedback** - Understand pain points, address them

---

## Deliverables

### Files to Create

1. **TestProject/.claude/agents/feature-implementation.md**
   - Adapted specialist agent
   - TaskMaster calls removed
   - DAIC mode checkpoint added
   - TDD workflow preserved

2. **cc_sessions/hooks/shared_state.py** (update)
   - Add suggest_specialist_routing() function
   - Task type analysis logic

3. **Documentation** (update)
   - USAGE_GUIDE.md: Add specialist section
   - routing-strategy.md: Update with test results
   - decisions.md: Document routing decisions

### Testing Artifacts

- [ ] Test Scenario 1 results (pure backend)
- [ ] Test Scenario 2 results (mixed work)
- [ ] Test Scenario 3 results (boundary violation)
- [ ] Test Scenario 4 results (mode protection)
- [ ] User feedback summary
- [ ] Routing accuracy metrics

---

## Timeline

**Week 2:**
- Day 1-2: Adapt feature-implementation agent
- Day 3-4: Implement routing logic
- Day 5-6: Test all scenarios
- Day 7: Fix issues

**Week 3:**
- Day 1-2: User acceptance testing
- Day 3-4: Documentation updates
- Day 5: Metrics collection and analysis
- Day 6-7: Final refinements, prepare for Phase 3

---

Last Updated: 2025-01-03

===== questions.md =====
# Open Questions - Integration Project

## Overview

This document tracks open questions that need resolution during the integration project. Questions are categorized and updated as decisions are made.

---

## Technical Questions

### Q1: Hook Integration Agent

**Question:** Should we use their @hook-integration-agent or manually create hooks?

**Context:**
- Their agent automates hook setup and configuration
- We already have a hook system in place
- Manual setup gives more control but takes more time

**Options:**
1. Adapt their hook-integration-agent to cc-sessions
2. Manually create hooks based on their patterns
3. Hybrid: Use agent for initial setup, manual refinement

**Decision:** TBD

**Impact:** Medium (affects Phase 3 implementation timeline)

---

### Q2: Test Runner Abstraction

**Question:** How complex should test runner abstraction be?

**Context:**
- Their TDD validation agent assumes `npm test`
- Users might have Python (pytest), Go (go test), Rust (cargo test)
- More abstraction = more complexity

**Options:**
1. Start with npm/Node.js only, expand later
2. Build abstraction layer from start
3. Let specialists detect test framework dynamically

**Decision:** TBD

**Impact:** High (affects TDD validation implementation)

---

### Q3: Context7 MCP Configuration

**Question:** How should Context7 MCP be configured in cc-sessions?

**Context:**
- Their research agent uses Context7 for documentation
- We need to integrate this with existing sessions-config.json
- Users might not have Context7 set up

**Options:**
1. Required dependency (installation fails without it)
2. Optional enhancement (graceful fallback)
3. Separate install step (user decides)

**Decision:** TBD (leaning toward Option 2 - optional)

**Impact:** Medium (affects Phase 1 research agent implementation)

---

### Q4: Research Cache Location

**Question:** Should research cache be per-task or global?

**Context:**
- Their system: `.taskmaster/docs/research/`
- cc-sessions: `sessions/research/` (currently undefined)

**Options:**
1. `sessions/research/` - Global research cache
2. `sessions/tasks/{task}/research/` - Per-task research
3. Hybrid: Global + task-specific

**Decision:** TBD

**Impact:** Low (just a path convention)

---

### Q5: Validation Gate Ordering

**Question:** What order should validation gates run?

**Context:**
- @tdd-validation-agent - Runs tests
- @enhanced-quality-gate - Security, performance, accessibility
- @completion-gate - Acceptance criteria validation

**Options:**
1. Sequential: TDD → Quality → Completion
2. Parallel: All gates run simultaneously
3. Conditional: TDD first, others only if passes

**Decision:** TBD (leaning toward Option 3)

**Impact:** Medium (affects validation workflow)

---

## UX/Workflow Questions

### Q6: Routing Confirmation Frequency

**Question:** How often should Claude ask for specialist confirmation?

**Context:**
- Every time could be annoying
- Never asking loses transparency
- User might develop preferences over time

**Options:**
1. **Always ask** - Every implementation requires confirmation
2. **Once per session** - First time explains, then remembers preference
3. **Configurable** - User sets preference in sessions-config.json
4. **Smart defaults** - Learn from user behavior over time

**Decision:** TBD (leaning toward Option 1 for Phase 2, Option 4 for Phase 5)

**Impact:** High (core UX decision)

---

### Q7: Specialist Refusal Handling

**Question:** What happens when specialist refuses out-of-scope work?

**Context:**
- Specialist detects boundary violation
- User already confirmed specialist usage
- Need to recover gracefully

**Options:**
1. **Auto-fallback** - Specialist refuses, Claude uses general implementation
2. **Re-route** - Ask user to pick different specialist
3. **Abort** - Stop and explain, user decides next step

**Decision:** TBD (leaning toward Option 3 - transparency)

**Impact:** Medium (affects error recovery UX)

---

### Q8: TDD Enforcement Strictness

**Question:** How strict should TDD enforcement be?

**Context:**
- Their system: RED-GREEN-REFACTOR mandatory
- Some users might want flexibility
- Quality vs flexibility trade-off

**Options:**
1. **Strict** - Specialists always enforce TDD, no exceptions
2. **Configurable** - User can disable TDD per specialist
3. **Soft enforcement** - Specialists suggest TDD but don't block

**Decision:** TBD (leaning toward Option 1 - that's the point of specialists)

**Impact:** High (core quality enforcement decision)

---

### Q9: Success Ceremony

**Question:** Should we add automated success celebration on task completion?

**Context:**
- Their system has success reporting templates
- Could auto-log completion reports
- Positive reinforcement for users

**Options:**
1. **Full ceremony** - ASCII art, completion summary, metrics
2. **Simple report** - Structured completion output
3. **Minimal** - Just update task status
4. **User choice** - Configurable per preferences

**Decision:** TBD (Phase 5 enhancement)

**Impact:** Low (nice-to-have feature)

---

### Q10: Multi-Language Support Priority

**Question:** When should we support non-JavaScript projects?

**Context:**
- Phase 2 proof of concept with npm/Node.js
- Python, Go, Rust users would benefit
- More complexity earlier vs delayed value

**Options:**
1. **Phase 2** - Build abstraction from start
2. **Phase 4** - After core specialists working
3. **Phase 5** - Enhancement phase
4. **Community** - Let users contribute language support

**Decision:** TBD (leaning toward Option 3)

**Impact:** Medium (affects implementation timeline)

---

## Process Questions

### Q11: Metrics Collection

**Question:** Should we integrate @metrics-collection-agent?

**Context:**
- Tracks hypothesis validation (do specialists improve quality?)
- Adds complexity and data collection
- Privacy concerns for some users

**Options:**
1. **Yes, from start** - Track everything from Phase 1
2. **Optional** - Users opt-in to metrics
3. **Phase 5** - Add after system stable
4. **Never** - No metrics collection

**Decision:** TBD (leaning toward Option 3)

**Impact:** Low (research benefit but not critical)

---

### Q12: Agent Naming Convention

**Question:** Should we rename their agents to match cc-sessions conventions?

**Context:**
- Their naming: `@feature-implementation-agent`
- cc-sessions naming: `context-gathering` (no @ prefix)
- Consistency vs recognition

**Options:**
1. **Keep their names** - Easier to reference source
2. **Rename to cc-sessions style** - Consistency
3. **Hybrid** - Keep specialist names, rename others

**Decision:** TBD

**Impact:** Low (just naming)

---

### Q13: Documentation Updates

**Question:** How should we document the new specialists for users?

**Context:**
- USAGE_GUIDE.md needs updates
- New users need to understand specialists
- Existing users need migration guide

**Options:**
1. **Comprehensive rewrite** - Full documentation overhaul
2. **Additive sections** - Add specialist sections to existing docs
3. **Separate guide** - New SPECIALISTS.md file
4. **Inline help** - Claude explains on first use

**Decision:** TBD (leaning toward Option 3 + Option 4)

**Impact:** Medium (affects user adoption)

---

## Integration Strategy Questions

### Q14: Phase 1 Scope

**Question:** Should Phase 1 include Memory Bank + Context7 integration?

**Context:**
- Research agent needs Context7 for documentation
- Memory Bank already integrated in cc-sessions
- Could combine for comprehensive research

**Options:**
1. **Context7 only** - Focus on new MCP integration
2. **Both** - Leverage existing Memory Bank + add Context7
3. **Neither** - Basic research first, MCPs later

**Decision:** TBD (leaning toward Option 2)

**Impact:** Medium (affects Phase 1 complexity)

---

### Q15: Backward Compatibility

**Question:** Must cc-sessions remain backward compatible during integration?

**Context:**
- Existing users have workflows established
- New features might change behavior
- Version bump implications

**Options:**
1. **Full compatibility** - No breaking changes ever
2. **Major version bump** - Allow breaking changes for better design
3. **Feature flags** - Old behavior available, new behavior opt-in

**Decision:** TBD (leaning toward Option 3)

**Impact:** High (affects implementation freedom)

---

## Priority Questions (Need Immediate Resolution)

### High Priority

1. **Q6: Routing confirmation frequency** - Affects Phase 2 UX design
2. **Q8: TDD enforcement strictness** - Core specialist behavior
3. **Q15: Backward compatibility** - Overall integration approach

### Medium Priority

4. **Q2: Test runner abstraction** - Affects TDD validation agent
5. **Q3: Context7 MCP configuration** - Affects research agent
6. **Q13: Documentation updates** - User adoption

### Low Priority

7. All other questions can be decided during respective phases

---

## Decision Process

### How Questions Get Resolved

1. **Research** - Check their implementation, user feedback, best practices
2. **Discussion** - Talk through trade-offs with user
3. **Prototype** - Build small proof of concept if needed
4. **Decide** - Document decision in decisions.md
5. **Implement** - Execute based on decision

### When to Decide

- **Before starting phase** - Questions critical to that phase
- **During implementation** - When question blocks progress
- **After user feedback** - When user input changes assumptions

---

## Question Template

**For adding new questions:**

### Q[NUMBER]: [Question Title]

**Question:** [One sentence question]

**Context:**
- [Background information]
- [Why this matters]
- [Current state]

**Options:**
1. [Option 1 with brief pros/cons]
2. [Option 2 with brief pros/cons]
3. [Option 3 with brief pros/cons]

**Decision:** TBD

**Impact:** High/Medium/Low (affects [what])

---

Last Updated: 2025-01-03

===== quick-reference.md =====
# Quick Reference - Integration at a Glance

## Executive Summary

Integrating 10 specialized agents from claude-code-sub-agent-collective into cc-sessions to add:
- Research-backed planning (discussion phase)
- Specialized TDD implementation (implementation phase)
- Multi-gate validation (completion phase)

**Timeline:** 6 weeks, 5 phases
**Current Status:** Planning complete, ready for Phase 1

---

## What We're Adding

### 1 Research Agent
- **research-gathering** - Context7 integration for current documentation

### 5 Implementation Specialists
- **component-implementation** - UI only (React, HTML, CSS)
- **feature-implementation** - Backend only (APIs, logic, services)
- **infrastructure-implementation** - Setup only (build, config, tooling)
- **testing-implementation** - Tests only (adds tests to existing code)
- **polish-implementation** - Performance ONLY (optimization, bundle size)

### 3 Validation Gates
- **tdd-validation** - Runs actual tests, blocks if failing
- **quality-gate** - Security, performance, accessibility
- **completion-validation** - Validates acceptance criteria met

### 1 Routing Solution
- **Human-confirmed routing** - Claude suggests, user confirms

---

## Core Principles

1. **Specialized agents = control, not complexity**
   - Each agent has ONE job with clear boundaries
   - More discipline = better quality

2. **Human-confirmed routing (never auto-route)**
   - Claude analyzes task type
   - Claude suggests specialist
   - User confirms or chooses general implementation
   - Transparency + control

3. **DAIC integrity maintained**
   - All implementation agents check mode before running
   - Discussion phase: Research only
   - Implementation phase: Specialists + validation

4. **TDD enforcement (RED-GREEN-REFACTOR)**
   - Max 5 initial tests (prevents over-engineering)
   - Tests FIRST, then minimal code
   - Refactor for quality

---

## Key Adaptations

### Remove TaskMaster MCP
```javascript
// BEFORE (their code):
mcp__task-master__get_task --id=1.2

// AFTER (cc-sessions):
const currentTask = Read('.claude/state/current_task.json');
const taskFile = Read(`sessions/tasks/${currentTask.task}.md`);
```

### Add DAIC Mode Checkpoint
```javascript
// Every implementation agent:
const mode = Read('.claude/state/daic-mode.json').mode;
if (mode !== "implementation") {
    return "❌ CANNOT PROCEED - Not in implementation mode";
}
```

### Update File Paths
```
.taskmaster/docs/research/ → sessions/research/
.taskmaster/tasks/         → sessions/tasks/
```

---

## Phased Rollout

### Phase 1: Research (Week 1-2) ✅ Planned
- Adapt research-gathering agent
- Context7 + Memory Bank integration
- Prove research improves planning

### Phase 2: Single Specialist (Week 2-3) ✅ Planned
- Adapt feature-implementation agent
- Implement human-confirmed routing
- Prove TDD enforcement works

### Phase 3: Validation Gates (Week 3-4)
- Adapt tdd-validation agent
- Adapt quality-gate agent
- Adapt completion-validation agent
- Wire into task completion

### Phase 4: Full Suite (Week 4-6)
- Adapt remaining 4 implementation agents
- Expand routing to all types
- Test specialist boundaries

### Phase 5: Enhancements (Week 6+)
- Success ceremony
- Multi-language support
- Metrics collection (optional)

---

## Routing Flow Example

```
User: "go ahead"
    ↓
DAIC unlocks implementation mode
    ↓
Claude: "This looks like backend work.

Should I:
1. Use feature-implementation specialist (TDD enforced)
2. Use general implementation (flexible)

Which would you prefer?"
    ↓
User: "1"
    ↓
Claude invokes specialist
    ↓
Specialist checks DAIC mode ✅
Specialist validates boundaries ✅
Specialist enforces TDD:
    RED: 5 tests written, all fail
    GREEN: Minimal code, all pass
    REFACTOR: Improved code
    ↓
Task complete with tests
```

---

## Specialist Boundaries

| Specialist | Can Do | Cannot Do |
|------------|--------|-----------|
| **component** | UI components, styling, interactions | Backend, APIs, setup |
| **feature** | APIs, business logic, services | UI, setup, optimization |
| **infrastructure** | Build config, dependencies, env | Features, UI, optimization |
| **testing** | Add tests to existing code | Modify implementation |
| **polish** | Performance optimization | Add features, change behavior |

**Boundary enforcement:**
- Specialist validates at start
- Refuses out-of-scope work
- Offers correct specialist
- User controls recovery

---

## Key Decisions

1. **D1: Adopt Specialized Agents** - More control = better quality
2. **D2: Human-Confirmed Routing** - Never auto-route, always ask
3. **D3: File-Based Tasks** - No TaskMaster, use cc-sessions files
4. **D4: DAIC Mode Checkpoints** - All specialists check mode
5. **D5: Phased Rollout** - 5 phases, prove value incrementally
6. **D6: Keep TDD Exactly** - Don't modify their proven workflow

See `decisions.md` for full rationale.

---

## Open Questions (High Priority)

1. **Q6: Routing confirmation frequency** - Always vs learned preferences?
2. **Q8: TDD enforcement strictness** - Strict vs configurable?
3. **Q15: Backward compatibility** - Breaking changes allowed?

See `questions.md` for all questions.

---

## Success Metrics

### Phase 1 (Research)
- Research accuracy: 90%+ relevant
- Context7 availability: Graceful fallback 100%
- User feedback: "Research improved understanding"

### Phase 2 (Specialist)
- TDD compliance: 100% tests first
- Boundary violations: 0
- Routing accuracy: 90%+ correct suggestions
- User feedback: "I trust the specialist"

### Phase 3 (Validation)
- Gates catch issues: >80% of problems detected
- False positives: <10%
- User feedback: "Validation saves time"

---

## Next Steps

### Immediate (This Week)
1. Review all planning docs with user
2. Resolve high-priority open questions
3. Start Phase 1: Research agent adaptation

### Week 1-2 (Phase 1)
1. Copy research-agent from their repo
2. Remove TaskMaster calls
3. Add Context7 + Memory Bank integration
4. Test all scenarios
5. Document learnings

### Week 2-3 (Phase 2)
1. Copy feature-implementation-agent
2. Remove TaskMaster calls
3. Add DAIC mode checkpoint
4. Implement human-confirmed routing
5. Validate TDD workflow
6. Test boundary enforcement

---

## File Reference

### Planning Docs (Complete)
- `readme.md` - Documentation overview
- `integration-plan.md` - Overall strategy
- `agent-inventory.md` - Agent catalog
- `adaptation-guide.md` - Step-by-step instructions
- `routing-strategy.md` - Routing specification
- `decisions.md` - Decision log
- `questions.md` - Open questions
- `phase-1-research-agent.md` - Phase 1 details
- `phase-2-single-specialist.md` - Phase 2 details

### Source Repository
- https://github.com/vanzan01/claude-code-sub-agent-collective
- Located at: `/Users/gabel/Desktop/Coding/Projects/Claude/cc-sessions/TestProject/claude-code-sub-agent-collective`

---

## Common Patterns

### Load Current Task
```javascript
const currentTask = Read('.claude/state/current_task.json');
const taskContent = Read(`sessions/tasks/${currentTask.task}.md`);
```

### Check DAIC Mode
```javascript
const daicState = Read('.claude/state/daic-mode.json');
if (daicState.mode !== "implementation") {
    // Refuse to proceed
}
```

### Extract Section
```javascript
function extractSection(markdown, heading) {
    const lines = markdown.split('\n');
    const startIdx = lines.findIndex(l => l.startsWith(heading));
    const endIdx = lines.findIndex((l, i) =>
        i > startIdx && l.startsWith('## ')
    );
    return lines.slice(startIdx + 1, endIdx === -1 ? undefined : endIdx).join('\n');
}
```

### Cache Research
```javascript
Write(`sessions/research/${timestamp}_${topic}.md`, researchContent);
```

---

## Risk Mitigation

### Risk 1: User Rejects Specialists
- **Mitigation:** Always offer general implementation fallback
- **Signal:** Track adoption rate, ask for feedback

### Risk 2: TDD Feels Too Slow
- **Mitigation:** Show value (bugs caught early), consider quick mode
- **Signal:** User feedback on process

### Risk 3: Routing Accuracy Low
- **Mitigation:** User confirms before invocation (built-in safety)
- **Signal:** Track misclassifications, improve detection

### Risk 4: Context7 Unavailable
- **Mitigation:** Graceful fallback to WebSearch
- **Signal:** Research quality metrics

---

## Documentation Standards

### File Naming
- ✅ lowercase-with-hyphens.md
- ❌ UPPERCASE.md or CamelCase.md

### Agent Naming
- ✅ feature-implementation (no @ prefix)
- ❌ @feature-implementation-agent

### Code Examples
- Use JavaScript pseudocode for clarity
- Show BEFORE (their code) and AFTER (cc-sessions)
- Include error handling examples

---

Last Updated: 2025-01-03

===== readme.md =====
# Collective Integration - Development Documentation

## Purpose

This folder contains planning, analysis, and implementation documentation for integrating specialized agents from claude-code-sub-agent-collective into cc-sessions.

## Project Goal

Evolve cc-sessions from simple DAIC (Discussion-Alignment-Implementation-Check) enforcement to a comprehensive quality-controlled development framework with:
- Research-backed planning (discussion phase)
- Specialized TDD-enforced implementation (implementation phase)
- Multi-gate quality validation (completion phase)

## Documentation Structure

### Core Planning Documents ✅

- **`integration-plan.md`** - Overall integration strategy and phases
  - Executive summary and philosophy
  - Agents being integrated (10 total)
  - Phased implementation approach (5 phases)
  - Key refinements from external review
  - Success metrics

- **`agent-inventory.md`** - Complete catalog of agents being integrated
  - Research agents (1): research-agent
  - Implementation agents (5): component, feature, infrastructure, testing, polish
  - Validation agents (3): tdd-validation, quality-gate, completion-gate
  - Status tracking and priorities

- **`adaptation-guide.md`** - Step-by-step adaptation instructions
  - Standard adaptation process (7 steps)
  - TaskMaster MCP removal patterns
  - DAIC mode checkpoint implementation
  - Common helper functions
  - Validation checklist

- **`routing-strategy.md`** - Routing logic specification
  - Human-confirmed routing flow
  - Task type analysis rules
  - User confirmation templates
  - Boundary enforcement patterns
  - Error recovery strategies

### Decision Tracking ✅

- **`decisions.md`** - All decisions made during integration
  - Architecture decisions (D1-D4)
  - Integration strategy decisions (D5-D6)
  - Technical decisions (D7-D9)
  - UX decisions (D10-D11)
  - Scope decisions (D12-D13)

- **`questions.md`** - Open questions needing resolution
  - Technical questions (5)
  - UX/workflow questions (5)
  - Process questions (3)
  - Integration strategy questions (2)
  - Priority categorization

### Phase Implementation Guides ✅

- **`phase-1-research-agent.md`** - Research agent integration
  - Goal: Prove research improves planning
  - Context7 + Memory Bank integration
  - Graceful fallback implementation
  - Testing plan with 3 scenarios
  - Timeline: Week 1-2

- **`phase-2-single-specialist.md`** - Proof of concept with one implementation agent
  - Goal: Prove specialist approach works
  - Feature-implementation-agent adaptation
  - Human-confirmed routing implementation
  - TDD workflow validation
  - Testing plan with 4 scenarios
  - Timeline: Week 2-3

### Future Phase Documents (To Be Created)

- `phase-3-validation-gates.md` - Quality gate integration (Week 3-4)
- `phase-4-full-specialists.md` - All implementation agents (Week 4-6)
- `phase-5-enhancements.md` - Polish and improvements (Week 6+)

### Technical Specifications (To Be Created)

- `agent-adaptations/` - Specific changes needed for each agent
- `hook-changes/` - DAIC hook updates required
- `config-changes/` - Configuration file updates

## Quick Links

- Source repository: https://github.com/vanzan01/claude-code-sub-agent-collective
- cc-sessions repository: [your repo]

## Current Status

**Phase:** Planning
**Next Step:** Create integration plan
**Blockers:** None
**Last Updated:** 2025-01-03

===== routing-strategy.md =====
# Routing Strategy: Human-Confirmed Specialist Selection

## Overview

This document specifies how cc-sessions will route work to specialized implementation agents while maintaining DAIC principles and user control.

**Core Principle:** Never auto-route. Always ask user to confirm specialist selection.

---

## Routing Flow

### Standard Workflow

```
User: "go ahead" / "make it so" / trigger phrase
    ↓
DAIC switches to implementation mode
    ↓
Claude analyzes current task
    ↓
Claude identifies task type (UI / backend / setup / tests / performance)
    ↓
Claude ASKS user:
    "This looks like [TYPE] work.

    Should I:
    1. Use [specialist-name] (TDD enforced, specialized workflow)
    2. Use general implementation (no specialist)

    Which would you prefer?"
    ↓
User confirms choice (1 or 2)
    ↓
Proceed with selected approach
```

---

## Task Type Analysis

### How to Identify Task Type

Claude reads current task file and analyzes:

1. **Success Criteria** - What deliverables are expected?
2. **Context** - What components/files are involved?
3. **Task Name** - Often indicates type (implement-ui, fix-auth, setup-build)

### Classification Rules

| Task Type | Indicators | Recommended Specialist |
|-----------|-----------|------------------------|
| **UI Component** | React/Vue components, styling, user interactions, CSS | `@component-implementation-agent` |
| **Backend Logic** | APIs, services, business logic, data processing, state management | `@feature-implementation-agent` |
| **Infrastructure** | Build config, dependencies, env setup, CI/CD, tooling | `@infrastructure-implementation-agent` |
| **Testing** | Adding tests to existing code, test suites, test utilities | `@testing-implementation-agent` |
| **Performance** | Optimization, bundle size, load times, memory usage | `@polish-implementation-agent` |
| **Mixed Work** | Multiple types (e.g., UI + API) | Offer general implementation OR sequential specialists |

### Edge Cases

**Mixed UI + Backend Work:**
```
Claude: "This task involves both UI components and API integration.

Should I:
1. Use general implementation (handles both)
2. Split into two phases:
   - Phase 1: Component specialist for UI
   - Phase 2: Feature specialist for API

Which would you prefer?"
```

**Unclear Task Type:**
```
Claude: "I'm not sure if this needs specialized handling.

Should I:
1. Use general implementation (flexible approach)
2. Let's discuss the approach first

Which would you prefer?"
```

**Quick Fix:**
```
Claude: "This looks like a small fix to [component/service].

Should I:
1. Just do it (general implementation)
2. Use [specialist] for proper TDD workflow

Which would you prefer?"
```

---

## User Confirmation Templates

### Template 1: Clear Specialist Match

```markdown
This looks like **[TYPE]** work.

**Suggested approach:**
Use `@[specialist-name]` which will:
- [Key benefit 1]
- [Key benefit 2]
- Enforce TDD (tests first, then implementation)

**Alternative:**
General implementation (more flexible, no TDD enforcement)

**Your preference?**
1. Use specialist
2. General implementation
```

### Template 2: Mixed Work

```markdown
This task involves **[TYPE1]** and **[TYPE2]** work.

**Option 1:** General implementation
- Handles both parts in one pass
- More flexible, less structure

**Option 2:** Sequential specialists
- `@[specialist-1]` for [TYPE1]
- `@[specialist-2]` for [TYPE2]
- TDD enforced for each phase

**Your preference?**
```

### Template 3: Quick Decision

```markdown
Quick routing question:

This looks like [TYPE] work. Use `@[specialist]`?
- Yes → TDD workflow, specialized approach
- No → General implementation
```

---

## Fallback Paths

### User Says "Just Do It"

```javascript
// If user says "just do it", "don't care", "your choice":
// → Default to general implementation
// → User wants quick action, not process overhead
```

### User Asks "What's the Difference?"

```markdown
**Specialist approach:**
- Strict TDD: Write tests FIRST, then code
- Max 5 initial tests (prevents over-engineering)
- Specialized for [domain]
- Clear boundaries (won't do [other-type] work)

**General implementation:**
- Flexible workflow
- You decide when/how to test
- Can mix UI/backend/setup as needed
- Less structure, more adaptability
```

### User Always Wants Specialist

```json
// Future enhancement: sessions-config.json
{
  "routing": {
    "default_to_specialist": true,
    "auto_route": false  // Always ask, even if default set
  }
}
```

### User Never Wants Specialist

```markdown
// If user consistently chooses general:
Claude: "I notice you prefer general implementation.
Should I stop asking about specialists for this session?"

// If yes → skip routing confirmation, use general
```

---

## Specialist Boundaries Enforcement

### What Happens If Wrong Specialist?

Each specialist has boundary checks:

```markdown
## Component Specialist Boundary Check:
1. Analyze task deliverables
2. If requires backend/API work → REFUSE
3. Error message:
   "❌ This task requires backend work.

   I'm the component specialist (UI only).

   Options:
   1. Use feature-implementation-agent for backend work
   2. Use general implementation for mixed work

   Which would you prefer?"
```

### Boundary Enforcement Pattern

```javascript
// In specialist agent prompt:

## Step 1: Boundary Validation
1. Load task: Read('sessions/tasks/${task}.md')
2. Check deliverables against specialization
3. If out of scope:
   - List what's in scope
   - List what's out of scope
   - Offer routing alternatives
   - REFUSE to proceed
```

---

## Routing Implementation

### Where Does Routing Live?

**Option A: DAIC Hook Logic**
- `sessions-enforce.py` detects implementation mode
- Adds routing prompt to system message
- Claude sees prompt, asks user

**Option B: Session Start Protocol**
- When implementation mode activated
- Show routing guidance
- Claude follows protocol

**Option C: Dedicated Routing Function** (Future)
- Helper function in shared_state.py
- Called by Claude when needed
- Returns formatted routing prompt

**Recommended: Option B** (simplest, no code changes)

### Implementation Steps

1. **Create routing protocol** (sessions/protocols/specialist-routing.md)
2. **Update DAIC unlock message** to reference routing
3. **Train Claude** through this documentation
4. **Iterate** based on user feedback

---

## Routing Decision Factors

### When to Suggest Specialist

✅ **YES - Suggest specialist when:**
- Task clearly fits one specialist's domain
- Task is non-trivial (>30min work)
- Task requires quality enforcement
- Task creates new functionality

❌ **NO - Skip specialist suggestion when:**
- Quick fix (<10min work)
- Debugging/investigation
- Documentation updates
- Config tweaks
- User has expressed preference for general

---

## User Learning Curve

### First Time Using Specialist

```markdown
Claude: "This is the first time I'm suggesting a specialist agent.

**What's a specialist?**
Specialized implementation agents that:
- Enforce TDD (tests first, then code)
- Have clear boundaries (UI vs backend vs setup)
- Follow structured workflows

**For this task:**
[Specialist suggestion with full explanation]

**Your preference?**
1. Try the specialist (I'll guide you through it)
2. Stick with general implementation (what you're used to)
```

### Nth Time Using Specialist

```markdown
Claude: "[TYPE] work detected.

Use `@[specialist]`? (yes/no)"
```

### User Becomes Expert

```markdown
User: "use component specialist"

Claude: "✅ Using component-implementation-agent"
// Skip confirmation, user knows what they want
```

---

## Error Recovery

### User Picks Wrong Specialist

```markdown
Specialist: "❌ Boundary violation detected.

This task requires [OTHER-TYPE] work, which is outside my scope.

Routing back to you for correct specialist selection..."

Claude: "The specialist couldn't complete this. Let's try:
1. General implementation (flexible)
2. [correct-specialist] (if clearly identifiable)

Which would you prefer?"
```

### User Regrets Specialist Choice

```markdown
User: "Actually, just do it normally"

Claude: "✅ Switching to general implementation.

(The specialist hasn't started yet, so no rollback needed)"
```

---

## Future Enhancements

### Phase 5+ Additions

1. **Smart Defaults**
   - Learn user preferences over time
   - Suggest based on history
   - Still always confirm

2. **Task Metadata Routing Hints**
   ```markdown
   ## Task Metadata
   suggested_specialist: component-implementation-agent
   routing_confidence: high
   ```

3. **Multi-Specialist Workflows**
   ```markdown
   Workflow:
   1. Component specialist → UI
   2. Feature specialist → API integration
   3. TDD validation → Tests pass?
   ```

4. **Voice-Based Routing** (if Claude Code adds voice)
   ```
   User: "use UI specialist"
   Claude: "✅ Component specialist activated"
   ```

---

## Testing Routing

### Test Cases

1. **Clear UI Task**
   - Task: "implement login form component"
   - Expected: Suggest component-implementation-agent
   - User confirms: Proceed with specialist

2. **Clear Backend Task**
   - Task: "implement auth service"
   - Expected: Suggest feature-implementation-agent
   - User confirms: Proceed with specialist

3. **Mixed Task**
   - Task: "implement user profile (UI + API)"
   - Expected: Offer general OR sequential specialists
   - User chooses: Respect choice

4. **Quick Fix**
   - Task: "fix typo in button label"
   - Expected: Suggest general (too small for specialist)
   - User can override if desired

5. **User Override**
   - Task: Any task
   - User says: "just use general implementation"
   - Expected: Skip specialist, use general

---

## Success Metrics

### Routing Success

- **Good routing:** User confirms specialist 80%+ of time
- **Bad routing:** User rejects specialist >50% of time
- **Great routing:** User starts requesting specialists by name

### User Experience

- **Transparency:** User always knows what will happen
- **Control:** User can always override
- **Learning:** User understands specialists over time
- **Efficiency:** Routing adds <30 seconds to workflow

---

Last Updated: 2025-01-03
